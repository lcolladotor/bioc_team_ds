[["index.html", "R/Bioconductor-powered Team Data Science Overview YouTube Code of conduct Team members Acknowledgements Join the team Twitter", " R/Bioconductor-powered Team Data Science Leonardo Collado-Torres Overview Welcome to the R/Bioconductor-powered Team Data Science group by Leonardo Collado Torres and team members! The purpose of this website is to serve as a guide for training new team members and colleagues on how we do R/Bioconductor-powered Team Data Science. As a team, we run Data Science guidance sessions where we help others navigate the world of data science. Through those sessions we identify concepts that we might need to explain better and this book is where we concentrate all our knowledge. Thus it is continuously modified and expanded. We often refer others to this specific chapters of this book, which in a way is a gloried collection of bookmarks with some of our own explanations. We constantly create new content to share what we are learning or working on, which you might be interested in. In particular, we: run the LIBD rstats club which you can find on Twitter as LIBDrstats (check the rstats club schedule) discuss papers and software in our team meetings (check our team schedule) organize R/Bioconductor data science bootcamps For an overview of our recent work, check this video and companion slides. YouTube You can find our videos on YouTube at lcolladotor/playlists. Some of our main video playlists are show below. LIBD rstats club Team journal club LIBD and team bootcamps Code of conduct We follow the LIBD conduct policies as well the Bioconductor code of conduct. The LIBD rstats club code of conduct is currently outdated and will be updated based on the Bioconductor code of conduct. Team members Cynthia S Cardinault Daianna González Hédia Tnani Louise A. Huuki-Myers Nicholas J. Eagles Renee Garcia-Flores Alumni Abby Spangler Amy Peterson Arta Seyedian Ashkaun Razmara Brenda Pardo Joshua M. Stolz Acknowledgements The contents of this book have been refined thanks to feedback from: Keri Martinowich Kristen R. Maynard With lessons learned from former mentors Jeffrey T. Leek and Andrew E. Jaffe. Join the team If you are interested in joining the R/Bioconductor-powered Team Data Science group, please check our open positions at the LIBD career opportunities website. You might be interested in checking our anonymous team survey results, which highlights some strengths but also some weaknesses and areas we can improve. If we don’t have any open positions, please reach out to Leonardo with your CV, GitHub/GitLab/etc profile with open-source software, and a short description of why you are interested in our team. Twitter You can find us on Twitter through the LIBD rstats club account and our own accounts where we share our work. Cynthia S Cardinault Daianna González Hédia Tnani Leonardo Collado Torres Louise A. Huuki-Myers Nicholas J. Eagles Renee Garcia-Flores Alumni: Abby Spangler Amy Peterson Arta Seyedian Askhaun Razmara Brenda Pardo Joshua M. Stolz Tweets by LIBDrstats "],["onboarding.html", "1 Onboarding 1.1 Basic work expectations 1.2 Background knowledge 1.3 Commonly used software 1.4 Team communication 1.5 Laptop setup 1.6 Commonly used software 1.7 Meetings of potential interest 1.8 Eating nearby 1.9 Baltimore Life", " 1 Onboarding If you are either new to my team or LIBD, you might this page useful. Note that each LIBD prinpical investigator (PI) might decide to do things differently. Some of the content here comes from jaffe_onboarding, which was actively used from Sep 8, 2019 till Sep 2020. On your first few weeks, you will be acquiring a lot of information about how we work, how we organize our work, where things are located, scientific background on the topic(s) you will be working on, as well as configuring your computer so you can work efficiently with the resources we have available. As part of this process, you will likely get a LIBD laptop and will need to spend time configuring it before you can use efficient workflow techniques. As you’ll see, there is a lot of information on this page and there’s going to be lots to learn for quite some time. We even have continuous learning activities, as new things come out all the time! Some of us have been doing this longer than others, but we all had to learn somewhere and want to make it easier for you. If you are overwhelmed, schedule a Data Science guidance session (DSgs) and we’ll help you get started by pointing you to the relevant parts appropriate to you. For example, we can help you make a list of useful resources or videos to watch from the LIBD rstats club schedule, as well as from the team presentations schedule; both are available as YouTube playlists. These videos help clone ourselves so we can reach more people. This follows the same idea about writing a blog post if 3 people ask the same question (more on this further below). When in doubt, schedule a DSgs! We only list when we are available, so if we are not, you’ll notice it on Calendly and don’t need to worry about it. Planning ahead is always useful and you should feel free to ask us for help. We like to help and the DSgs help both you and us: we want to make it easy for you to schedule DSgs sessions, while we also need to do other things and thus need to limit when we are available. 1.1 Basic work expectations This might be your first job experience which is very exciting, but also different from being a student. You will thus need to learn to work in our team and maybe adapt some of your behavior. Ultimately, communication will be your friend to avoid any misunderstandings such as different expectations. There are also some rules you will have to follow, which are aimed at making sure we all are on the same playing field. The following are some team guidelines I have, but you should also read the LIBD Employee Handbook which you can find through Paylocity under the “Company” section after you log in. Work 40 hours per week. The employee handbook states: The Lieber Institute’s normal business hours are 8:30 a.m. to 5:30 p.m., Monday through Friday with an hour included for lunch and breaks.. That’s exactly 8 work hours per day, and 40 work hours per week. You can measure this by installing the free version of RescueTime. Minimize all distractions on the 8 work hours. Avoid checking social media or any other lurking activities. You can put your phone in “work mode” (“focus” for iPhone) to silence all notifications as well. If you need to do something else, notify me or request time off through Paylocity when appropriate. Aim to achieve a weekly productivity score on RescueTime of 70 or above (ideally over 80). I have docs.google.com/#document, terminal (iterm2), and rstudio listed as “very productive”. Then slack, mail.libd.org as “productive”. I have zoom.us as “very distracting” since I’m personally trying to de-incentivize having meetings all day, but for you that might be different. Independently perform basic job responsibilities without instruction. Keep a notebook with you to take notes when necessary. Maintain ongoing list of daily to do items. Optionally post your to dos on the respective Slack channels by 9:30 am each morning (10:30 am when we have 9-10 am meetings). Doing so can help the most in your first few months at the team, so we can identify how to best help you. Write code daily and version control it on Git/GitHub. If writing academic papers, then post equivalent updates on Slack. Make at least 10 commits per day, with 15 per day being the ideal number. That’s from 5 commits per 2 hour coding session as noted at “project feedback”, with at least 3 such sessions per day. If you spend time writing part of an academic manuscript, then post bullet point updates on the respective Slack channel. If you spend more than 15 minutes trying to solve something and are not making any more progress, ask a question about it on a Slack channel (not direct messages) with as much information needed to help you. Don’t use direct messages (DMs) on Slack, as multiple people can very likely help you and they won’t be able to do so through DMs. For R code, remember to use reprex like we mention at “how to ask for help”. You could also request help sessions from team members through the Data Science guidance sessions system. Communicate your reasoning and thought process. Respond to your colleagues in appropriate time windows. Don’t assume others know what you are thinking: be as verbose as possible. Avoid one liner replies on emails and Slack. Respond to Slack messages within a business hour and to emails from colleagues within a business day. CC me on all replies you send via email. Write a summary after every 1 on 1 meeting. Doing so reduces the burden on memorization. Write a bullet point list or make some GitHub issues after every 1 on 1 meeting you have with me or other colleagues. Comply with your “at the office” schedule. The exact days will depend on which days you have approval for working remotely (if any at all). Read at least one relevant scientific manuscript per week. Write a summary about it on the appropriate Slack channel. Relevant manuscripts are those explaining software/methods you are using, those related to the biological question you are working on, or new software/methods we might want to use for the projects you are working on. Work on your main projects at least some portion each day. Avoid cramming work the day before a meeting for a given project. Working the same amount of hours spread throughout the week allows you to identify questions and problems you might need help with, and to have the time to get the required help. I like having blocks of 2 hours where I work on a given project during 1 block of time. Switching projects too frequently is detrimental since it takes some time to refresh your memory and load the relevant data. 1.2 Background knowledge Below is a list of papers that might provide some useful background information for bulk RNA-seq or DNA methylation. We will also give you a more updated list of background papers to read depending on the project you will be working on. You might find some relevant papers and videos on the team presentations schedule and companion YouTube playlist. For example, check this presentation by Louise A. Huuki-Myers on the Cobos et al, Nature Communications, 2020 deconvolution paper. 1.2.1 RNA-seq RNA-Seq: a revolutionary tool for transcriptomics Advancing RNA-Seq analysis Differential gene and transcript expression analysis of RNA-seq experiments with TopHat and Cufflinks TopHat: discovering splice junctions with RNA-Seq TopHat2: accurate alignment of transcriptomes in the presence of insertions, deletions and gene fusions Systematic evaluation of spliced alignment programs for RNA-seq data Assessment of transcript reconstruction methods for RNA-seq Transcriptome and genome sequencing uncovers functional variation in humans Reproducibility of high-throughput mRNA and small RNA sequencing across laboratories 1.2.2 DNAm Note that we don’t work much with DNAm data nowadays, unlike the jaffe_onboarding days. However, this list might still be useful for some. Measuring cell-type specific differential methylation in human brain tissue From promises to practical strategies in epigenetic epidemiology A data-driven approach to preprocessing Illumina 450K methylation array data Epigenetic memory in induced pluripotent stem cells The human colon cancer methylome shows similar hypo- and hypermethylation at conserved tissue-specific CpG island shores Bump hunting to identify differentially methylated regions in epigenetic epidemiology studies Analysing and interpreting DNA methylation data DNA methylation: roles in mammalian development The Key Role of Epigenetics in Human Disease Prevention and Mitigation Charting a dynamic DNA methylation landscape of the human genome Global Epigenomic Reconfiguration During Mammalian Brain Development Divergent neuronal DNA methylation patterns across human cortical development: Critical periods and a unique role of CpH methylation 1.3 Commonly used software We use quite a bit of different software and while we list out some here below, you will want to check the LIBD rstats club schedule and companion YouTube playlist for more recent videos that might be relevant to your situation. For example, this video talks about RStudio and key packages like: usethis, here, and sessioninfo. 1.3.1 bash and linux You will need to learn the basics of bash and linux as we work a lot with the high performance computing cluster named JHPCE, which is a linux cluster. A computing cluster is basically a collection of machines (with no monitors) that have more memory than your regular laptop and that you can use for hours/days. That way, you are not limited by the specific properties of your laptop for most of our work. Linux essentials The Unix Workbench by Sean Kross. Rsync (Remote Sync): 10 Practical Examples of Rsync Command in Linux. Linux file permissions. How To Use Linux Screen – website 1 and How To Use Linux Screen – website 2. 1.3.2 R We use R quite a bit, and that’s actually how this website was made. Here are some useful resources, though you will eventually want to check the R/Bioconductor Data Science bootcamps and related resources. Download and install R from CRAN. R 101 LIBD rstats blog post by Carrie Wright. Download RStudio Desktop. Using the RStudio Terminal. RStudio cheatsheets for many things including regular expressions, purrr for functional programming, etc. Building Tidy Tools workshop materials by Charlotte Wickham and Hadley Wickham for the rstudio 2019 conference. Materials from other workshops is available here. R Markdown documentation website announced by Alison Hill. Cookbook for R graphs, 2nd edition with useful ggplot2 code. Updating R blog post, though also check more recent resources on the LIBD rstats club Google Sheet. Tutorial for building R websites by Emily C Zabor. More on R Markdown websites here, which is how this website was made. 1.3.3 python You can use RStudio for Python syntax highlighting and to run code through the integrated terminal window on JHPCE. reticulate might be of interest if you are working with Python from R. If you are writing an R package that will use Python internally, check out basilisk. If you want to open SummarizedExperiment objects in Python as AnnData objects, you might be interested in zellkonverter. 1.4 Team communication Overall, it’s important to ask for help. We try to follow the advice from the you must try, and then you must ask blog post. Also try to ask in a Slack channel where others might be able to benefit from your answers in the future. If enough people ask about something, we’ll try to write a blog post as advised here by David Robinson. For more details, see the “how to ask for help” page. 1.4.1 Zoom When on a team meeting Zoom call and most importantly, on one on one meetings, please have your camera on. Otherwise it feels like you are talking to the void. There are of course good reasons to turn off your camera, like if your internet connection is slow and you are presenting. Turning your camera on also incentives you to pay closer attention. Thank you! 1.4.2 GitHub LieberInstitute is our GitHub organization account. After you’ve made your GitHub account let your PI, Bill Ulrich or Leonardo Collado-Torres know about your username through Slack so they can add you to the relevant teams. GitHub issues are a useful way to specify tasks for a given project. As an example, check the libdRSE project. git to know git: an 8 minute introduction LIBD rstats blog post by Amy Peterson. Happy Git and GitHub for the useR book by Jenny Bryan, Jim Hester and other TAs. Videos by Jacob Fiksel on how to use Git for Windows and Mac. BFG Repo-Cleaner for fixing GitHub repositories that have data files (example, large files) that you want to delete from your history. Use the JHPCE LIBD module for bfg with module load bfg. Commit together with co-authors such that everyone gets recognized GitHub activity for joint work. Closing issues using keywords in commit messages. Merging a pull request. Also check this comment by Yihui Xie on how to best submit pull requests. Yihui Xie wrote two blog posts related to that particular series of pull requests here. Feel free to make pull requests to edit the contents of this website! Syncing a fork. How can I undo git reset –hard HEAD~1?. Contributing to the LIBD rstats club blog post if you want to write another LIBD rstats blog post or use blogdown. 1.4.3 Slack We have multiple Slack workspaces, though the main one we use is the JHU Genomics Slack which has over 500 members across many JHU and LIBD genomics teams. Ask your PI or Leonardo Collado-Torres to add you to that Slack workspace. Our main team channel is #libd_team_lcolladotor. Using Slack for Academic Departmental Communication blog post written by Leo and Stephanie Hicks. Preferably ask questions on a project channel such that others involved in the project are able to contribute answers. If it’s a more general question, try asking in the #libd_helpdesk channel. Beyond our team, you might want to ask for R help at #rstats and JHPCE help at #jhpce. You might also want to check out #jobs, #jhu_papers, #general, #funding, #diversity, #conferences, #random, #langmead_rss, among many others. For a new project, create a private channel with the prefix libd_ then invite the team members who are working on the project or might be able to help. To integrate a GitHub repository with a Slack channel type in the channel the command /github subscribe LieberInstitute/RepoName. Slack supports Markdown syntax for your messages, in particular we use a lot the backtick for inline code and the code chunk syntax for multi-line code. Examples: `inline code` example ``` multi line code example ``` renders into: inline code example multi line code example 1.4.4 Team calendar We have a team Google Calendar. Ask Leonardo Collado-Torres via Slack to add you to the calendar with your Google account email address (could be your libd one or could be a gmail account). The calendar is linked to #libd_team_lcolladotor and sends reminders to that channel 30 minutes before an event happens. 1.4.5 Academic Twitter Tackling Twitter as a Graduate Student blog post. 1.5 Laptop setup The “config files” page contains some relevant links that can help you find some software we frequently use or configuration files. Overall, we use frequently: R RStudio: for writing R/Python code, executing it at JHPCE through the integrated terminal. Cyberduck or WinSCP for browsing JHPCE files and previewing PDF files. Git: for version controlling files. See the install git chapter from Happy Git and GitHub for the useR. GitHub: for sharing our code within the team and externally, plus to transfer code between your laptop and JHPCE. TextMate or Sublime Text or some other text editor that has code syntax highlighting. RStudio has this too. JHPCE modules: for having a common installation location at JHPCE for software we use. See jhpce_mod_source and jhpce_module_config for more details. 1.5.1 JHPCE Since most analyses we run involve resources larger than those in our laptops, we typically used a high performance computing environment. Particularly, JHPCE. Note that the only official pronunciation for JHPCE is by its letters J-H-P-C-E. 1.5.1.1 JHPCE account One of the first things you’ll do is get a JHPCE account: under “sponsoring organization” scroll all the way down till you find the LIBD PIs such as “Martinowich” (applicable also for members of Stephanie Page and Kristen Maynard’s teams) or “Torres” for Leonardo Collado-Torres. You will receive an email with a private link to schedule your appointment at one of the training sessions for new users. They typically have space for 8 people and do the training sessions once every 2 weeks, so you will want to do this early as it can take a while to setup. Even if you are not going to write code but want to see some plots others have made, you will need to get your JHPCE account. 1.5.1.2 JHPCE setup Once you have your JHPCE account, you will want to set up your laptop and JHPCE to work efficiently. You highly encourage that you use some of the configuration files from the “config files” page. Check the LIBD rstats club videos on JHPCE laptop configuration. Though I also highly encourage you to schedule a Data Science guidance sessions to have someone check your configuration files. macOS: macOS setup, which included troubleshooting some steps. macOS &amp; winOS: some macOS and some winOS users joined us for this practice session. winOS: this is a very long video, but everything is eventually covered. Setup password-less login through ssh key pairs. You will need 4 key pairs. One key pair for your laptop to the JHPCE login node. One key pair from the JHPCE login node to the compute nodes (typically created by JHPCE admins). One key pair from your laptop to GitHub; see their documentation. One key pair from JHPCE to GitHub. You should edit your JHPCE ~/.bashrc and create your JHPCE ~/.inputrc file following the information we have at the “config files” page. You might want to do something similar for your macOS ~/.bashrc file. Though I lately use a ~/.zshrc file on my macOS computer. You should specify your email on your JHPCE ~/.sge_request file following the information we have at the “config files” page. You should edit your laptop’s and JHPCE ~/.gitconfig files following the information we have at the “config files” page. We will want to email BitSupport to make sure that your default user group is not users, but a more appropriate group such as lieber_lcolladotor or lieber_marmaypag. You will likely want to configure your laptop &amp; JHPCE to be able to use rmate to open JHPCE files from the terminal window in TextMate / Sublime Text / other text editors. This will involve editing your laptop’s ~/.ssh/config as well as your JHPCE’s ~/.ssh/config files. See the video below for more information about this process. You might be interested in configuring rmote to emulate the RStudio plot and help file panels. This will also involve editing your laptop’s ~/.ssh/config as well as your JHPCE’s ~/.ssh/config files. You will likely want to edit your laptop’s and JHPCE ~/.Rprofile, ~/.Renviron configuration files following the information we have at the “config files” page. 1.5.1.3 JHPCE info Now that you have your JHPCE account and can access files, you’ll want to get familiarized with many parts of JHPCE. You can see the archive of questions people have asked through bithelp and/or the #jhpce channel. Environment modules are useful so you don’t have to install some common software from scratch, such as R which you can load using module load conda_R. Use LIBD modules which you can setup following these instructions. jhpce_mod_source and jhpce_module_config are our GitHub repositories for our LIBD modules. Edit your bashrc file for a nicer terminal experience blog post. See the “config files” page for the latest common configuration files we use. sgejobs (documentation): contains helper functions for writing and interacting with SGE jobs at JHPCE. Array and Sequential Cluster Jobs. See also sgejobs::job_single(). Setting up your computer for bioinformatics/biostatistics and a compedium of resources 2012 blog post. Includes some Mac and Windows tools. Login to the cluster, request a node and change to your project directory in a single command 2013 blog post. me: Bad rm, don’t delete stuff I didn’t want to delete! (rm: well, I do what you tell me to do!) 2012 blog post. Automatically coloring your R output in the terminal using colorout blog post on colorout which you can access through jalvesaq/colorout nowadays and install with remotes::install_github('jalvesaq/colorout'). See “config files” page for the latest configuration files 1. There were a lot of miscellaneous things about using JHPCE that might save some confusion if you knew now: there’s a 100G storage limit on your home directory /users/[yourusername]/, which will likely fill up very quickly. Most of us have directories under the /dcs04, /dcl01, and /dcl02 filesystems, where there is far more space. you generally will want to include the -cwd flag in bash scripts. By default, it will default to dumping output files in your home directory, regardless of where you submit the script. for scripts/jobs where you are generating large files, you will need to change the maximum writable file size. This is the h_fsize flag for bash scripts, which defaults to 10G. See https://jhpce.jhu.edu/knowledge-base/how-to/ for more details. 1.5.2 macOS Cyberduck for accessing files remotely. With it, you can open any R files at JHPCE with RStudio in your laptop, then open a terminal from RStudio so you can execute your code. Alfred for quickly finding files among many other powerful workflows. I highly recommend paying for the power pack, to get access to the most advanced (and time saving) features. Textmate setup (Mac only) LIBD rstats 2018 blog post; it’s an alternative to using RStudio. The blog post also explains rmate which now also exists as a LIBD module that you can load with module load rmate at JHPCE. There’s also a more recent video on this topic on the LIBD rstats club Google Sheet. CriticMarkup. Mac keyboard shortcuts. 1.5.3 winOS WinSCP for browsing JHPCE files, previewing PDF files, opening R files on RStudio, etc. putty (which comes with WinSCP), for accessing JHPCE through a terminal window. MobaXTerm combines SSH and SFTP functionality and is fairly simple to set up and use. git for windows which includes Git Bash. Check rstudio issue 2224 for specifics on how to install Git Bash such that it will work with RStudio terminal. 1.5.4 Any OS For both macOS and winOS, you might be interested in this older (2012) blog post about my computers setup. 1.6 Commonly used software You will find a lot of more recent videos an materials for the topics below on the LIBD rstats club schedule / YouTube playlist. See the Overview page for more details. For example, you might enjoy the video about Bioconductor or the one on SummarizedExperiment / SingleCellExperiment. 1.6.1 Bioconductor Where do I start using Bioconductor? blog post. How to ask for help for Bioconductor packages blog post. Bioconductor workflows such as rnaseqGene and sequencing are very helpful to get started in the RNA sequencing (RNA-seq) field. BioC2019 workshops are available here. More recently, you might want to use Orchestra to find recent workshops and even access them interactively. limma: is one of the main packages we use for analyzing data, particularly with the limma-voom method. Check the Bioconductor workflows that explain limma in more detail here. GenomicRanges: is the package we use for interacting with genomic data across ranges. Check the introduction for more information. SummarizedExperiment: is the package we use for creating and interacting with RangedSummarizedExperiment objects. bsseq: is highly useful for analyzing DNA methylation data, particularly whole genome bisulfite sequencing (WGBS) data. Biostrings: is useful for dealing with sequence information such as the human genome sequence. 1.6.2 Lab software jaffelab (documentation): contains several functions we’ve written over the years that we find helpful for different analyses. sgejobs (documentation): contains helper functions for writing and interacting with SGE jobs at JHPCE. We have several videos on sgejobs at the rstats club schedule. jhpce_mod_source and jhpce_module_config are our GitHub repositories for our LIBD modules. shinycsv: allows interactively exploring a table. megadepth by David Zhang, Christopher Wilks, et al is an R package for dealing with BigWig files. Check also the older recount.bwtool. LIBD RNA-seq processing pipeline: SPEAQeasy, and SPEAQeasy-example. See also the initial version. globus: our Globus share endpoints such that others can access our data. 1.7 Meetings of potential interest LIBD rstats club described in more detail on this blog post. Joint genomics meeting: check the #joint_group_meeting channel for more information about this bi-weekly (every 2 weeks) meeting across multiple JHU labs. Baltimore R Ladies: check the #r-ladies Slack channel as well as meetup.com/rladies-baltimore/. They also have a website with code from earlier sessions and you can find the slides here. JHU Genomics events: check their calendar here. Every year they organize a symposium around October where you can present a poster if you want. They also organize other workshops which you might be interested in signing up for. 1.7.1 Conferences BioC: announced here. ASHG: website. CSHL Biology of Genomes (BoG) or Biological Data Science (BDS): through the CSHL website. RStudio conf: website. Women in Data Science (has multiple meetings), website. Joint Statistical Meetings (JSM): through the ASA website. See the conferences/courses of interest Google Sheet for more up to date information. 1.8 Eating nearby North East Market: it’s on 2101 E Monument St which is just a few minutes away walking. You can find a lot of variety there including a Korean stall along the south wall. That stall is pay-by-weight and lots of the dishes are delicious. School of Public Health 9th floor salad bar Garden Plate: walk two blocks north to 615 N Wolfe St or K 3-4 on the Hopkins East Baltimore Campus map, then take an elevator on the south side of the building to the 9th floor. The elevators on the north side don’t go all the way up to the 9th floor. 2 Kabobi: Afghan food, really quick for take-out. Popular choices are the lamb or chicken rice bowls, chopped salads, and the veggie rice bowls. Greenhouse: This is in neighboring Preclinical Teaching Building (PCTB); it’s on K2 on the Hopkins East Baltimore Campus map. Have someone show the inside way - or go outside and it’s just inside the Wolfe/Monument corner entrance. It’s a pay-by-weight buffet with salad bar and hot options. Not amazing but great lower cost option, especially if you are going for the lighter weight foods like salad! 1.8.1 Food trucks Koco - Korean food on Tuesdays and Fridays. A lab favorite! Favorites are bulgogi (beef) and tofu dishes. Chowhound - burgers (incl. veggie). Other good ones: Greek truck, Kabob/falafel truck in front of Starbucks 1.8.2 Other Food court inside the hospital with Subway, Einstein Bros, and others. It’s on G-H 4 on the Hopkins East Baltimore campus map. There’s a second one at I6 on the same map. Dunkin, Subway, and Chinese places along Monument St. 1.9 Baltimore Life “So you’re moving to Baltimore” 2013 blog post by Brian Caffo. The Baltimore Symphony Orchestra has discount tickets which you might be interested in. Live Baltimore for relevant information that might be useful prior to buying a home. Outdated: Check Leo’s JHPCE configuration files here.↩︎ I haven’t checked if it survived the COVID-19 pandemic or got replaced.↩︎ "],["data-science-guidance-sessions.html", "2 Data Science guidance sessions 2.1 Interaction rules 2.2 Help us help you 2.3 Sign up 2.4 DSgs session reports 2.5 Become a DSgs guide", " 2 Data Science guidance sessions Data is abundant in many aspects of our research work thanks to high-throughput experimental assays. While some analyses will require a significant amount of time from people who primarily do that type of work, we know that many of us are interested in learning more about working with data. As such, as a team, the DSgs-guides will provide Data Science guidance sessions (DSgs). These are 25 minute sessions where we’ll try our best to help you, teach you, troubleshoot with you, and overall guide you as much as we can. DSgs sessions are particularly helpful if you want to work on a data problem or gain some data skills across a period of weeks or months. Working with data and programming languages can have a steep learning curve and it can feel daunting. As a team, we have trained ourselves to have a common baseline and can help you get familiarized with the concept of a project-oriented workflow. This involves tools such as RStudio, git/GitHub, how to organize your code, how to ask for help, and overall tools to make your work more reproducible. These ideas when put into practice are very helpful for finding why things are not working, as we all inevitably encounter errors in our code and the open source software we rely on. Sometimes we won’t know the answer either, but maybe we can help you construct more specific Google search terms. Check the following slides for some of the initial ideas behind these sessions. Our philosophy and overview on the help we provide was described in this video and slides. 2.1 Interaction rules In order for DSgs sessions to run smoothly, it’s important that we have clear expectations of what we’ll do. DSgs sessions are not consulting sessions. We will help you as much as we can during the session, but after it’s over, we won’t spend time writing new code for you. That is, we will not take requests for work you need help finishing regardless of how important it is. That’s why we recommend planning ahead and even having weekly DSgs sessions if you have a deadline in mind instead of approaching us for help the week the project is due. We are most helpful early in a project cycle than at the end. We understand that you might be stressed or under significant pressure, but please follow our code of conduct 3. Otherwise, we will forced to stop meeting with you. 2.2 Help us help you When you sign up for a session, you will fill a small form where you can provide some information about why you want to meet. We will spend up to 15 minutes preparing for a session, and in order to make better use of that time, it is important that you provide us enough information so we can do a better job helping you. 2.2.1 Framing a question Just a reminder that you should read 3 💎s by @rdpeng* What is the question? https://t.co/Aet2wvBP5c w/ @jtleek* Tukey, Design Thinking, and Better Questions https://t.co/xyh5QZtnpQ s/o @hspter* Types of questions https://t.co/gqyJyTK8Zd w/ @elizabethmatsui #DataScience ❓ pic.twitter.com/tXlioGa3n9 — 🇲🇽 Leonardo Collado-Torres (@lcolladotor) June 2, 2022 Instead of saying “I need help”, it will be useful for us if you can be more specific. For example, “I need help with jaffelab::cleaningY()” or “I need help installing the Bioconductor package SummarizedExperiment on a Windows machine”. The first example lets us know that exact function you need help with, so we can revise the documentation before hand and come prepared to the meeting. The second example mentions a specific R package, where to find it (Bioconductor), and what operating system you are using. Here are some more example help requests: I want to learn how to use R, where should I start? I finished the CBDS lesson on using GitHub but I need help using git at JHPCE. I have some data that I generated and want to explore it. Which plots should I make? A collaborator suggested a specific linear regression model (~ age * brain region), can you explain to me how to interpret the results? Which R package should I use for performing a gene ontology enrichment analysis? I’m interesting in using software xx you wrote, can you help me understand how to do yy with it? I like the visualization you made for project xx, can you help me make a similar one with my data? I want to adapt code xx your team wrote in the past and use it in my project, can you help me get started Note that we’ll use the information you provided us for our DSgs session reports. We will keep your name anonymous and remove any private information. 2.2.2 Useful information As problems get more specific, we will require more information. If you are encountering an R error that you need help with, providing a small reproducible example will make the whole experience much smoother. The R package that is very useful for providing such examples is reprex. You can watch our LIBD rstats club video on reprex to get more familiarized with this package. To share code with us, Please create a gist which can be either public or private. In the gist include all the commands you ran and the output you got. Or provide the reprex code (preferred option). If you are already using GitHub for version controlling your code, then include the link to the script you are running. If you have a companion log file at JHPCE, please share the full path to the log file 4 Ideally include the R session information which you can generate using options(width = 120); sessioninfo::session_info(). This information will be particularly useful for solving issues with cutting edge R/Bioconductor/GitHub packages. 2.3 Sign up If you are interested in a 25 minute Data Science guidance session, please sign up through the Calendly links below with a session with one of our guides. If this is the first time you are using this or might need more general guidance, sign up with Leo. If you have a Zoom account, please add the Zoom details to the calendar invitation 5. Finally, please sign up for a maximum of two sessions per week. This will help us keep the DSgs system fair for everyone to use. Thank you! Guides are shown in order of their availability (most to least). Please try reaching out to multiple people instead of one person for all your questions. Thank you! Cynthia Soto Cardinault (BioC Support) Research interests: bulk RNA-Seq, workflows, machine learning methodologies. Technologies I use: bulk RNA-Seq, linux, python, R/WGCNA and github. Learning about: snRNA-Seq, multi-omics, snATAC and deconvolution. Calendly Hédia Tnani (BioC Support) Research interests: Bulk RNA-seq, scRNA-seq, building computational pipelines. Technologies I use: R/Bioconductor, Python, GitHub, Nextflow. Learning about: Functional programming, deconvolution, package development, omics integration. Calendly Madhavi Tippani (BioC Support) Research interests: spatial transcriptomics, calcium imaging, RNAscope, medical image processing. Technologies I use: Matlab, R, GitHub, SGE/JHPCE. Learning about: Machine Learning, spatial transcriptomics, statistical analysis. Calendly Nicholas J. Eagles (BioC Support) Research interests: bulk/single-cell RNA-seq, spatial transcriptomics, building computational pipelines. Technologies I use: R/Bioconductor, Git, Nextflow, python. Learning about: data visualization, deep learning. Calendly Louise A. Huuki-Myers (BioC Support) Research interests: bulk and single cell RNA-seq, spatial transcriptomics, RNA scope data, DEGs, data visualization. Technologies I use: R (tidyverse, ggplot, dplyr), Python, GitHub, Synapse upload. Learning about: Bioconductor Package development. Calendly Leonardo Collado-Torres (BioC Support) Research interests: RNA-seq, spatial transcriptomics, un-annotated transcriptome, deconvolution. Technologies I use: R/Bioconductor, GitHub, SGE/JHPCE. Learning about: team management, multi-omics. Calendly 2.4 DSgs session reports If you are interested in public information from our past sessions, check DSgs_logs, and in particular, some of our graphs. 2.5 Become a DSgs guide Non-team members are welcome to join the DSgs-guides. This involves a significant time commitment (~ 7 hours per week) and you need to discuss this with your supervisor. These commitments are: helping others through DSgs sessions ~ 200 minutes per week 6 a weekly 30 minute meeting as explained in DSgs: feedback attending the LIBD rstats club (1 hour per week) time for self-learning and/or building common resources (~ 1 hour per week) (recommended) practice and learn how to help others through the Bioconductor Support: practice grounds (~ 30 min per week) Additionally, we might have some additional training sessions. Some potential advantages are: access to all our training material, explained in detail at DSgs-guides a common structure for helping others at LIBD/JHU recognition through our DSgs session reports We will update the code of conduct once Bioconductor publishes their latest code of conduct in the Fall of 2020.↩︎ You might want to use the sgejogs package for helping you create such log files.↩︎ If you are using Google Calendar, there is a Google Calendar Zoom integration. The Outlook version LIBD uses does not support the Zoom integration, so you’ll have to add the information manually to the calendar invitation.↩︎ We recommend four 25 minute sessions, each with 15 minutes of preparation and 10 minutes of post-meeting wrap up.↩︎ "],["how-to-ask-for-help.html", "3 How to ask for help 3.1 General guidelines 3.2 Learning from our search history 3.3 Bioconductor Support website 3.4 RStudio Community website 3.5 GitHub 3.6 GitHub issues 3.7 Mailing lists 3.8 Slack", " 3 How to ask for help In our area of work, we will frequently run into code error messages as well as work with concepts that span multiple research fields including neuroscience, genomics, and bioinformatics. Thus, it is completely natural that we’ll need to ask others for help. We do this so frequently, that we end up developing skills for searching for the information that we need. Most of the times, we can spend a bit of time ourselves searching for a solution as described in more detail in “you must try, and then must ask”. Though at some point, we will ask others for their direct input. Many of the communication tools we use for asking for help are text-based. It can be hard to convey jokes, so sometimes it’s best to refrain from making jokes in order to prioritize a clear exchange of ideas. You should also be respectful of everyone’s time and with the words you choose. For example, see what Jim Hester has to say about issue titles: Take time⌚️to think about your issue titles!!! xyz is brokenvs xyz fails with malformed inputThe former puts the maintainers in a foul mood 😡Issues should be requests 💐 rather than demands 🔨 — Jim Hester (@jimhester_) January 11, 2021 Actually, Jim Hester keeps providing excellent advice, so you might want to check this table he made and shared on Twitter. We highly recommend that you watch Jenny Bryan’s RStudio Conf 2020 keynote talk titled “Object of type ‘closure’ is not subsettable” available through RStudio’s website. You can find all related links from her talk through GitHub. Object of type ‘closure’ is not subsettable - RStudio Ultimately, some coding issues are complex. Here are some tips on some strategies for resolving complex coding problems. 3.1 General guidelines In general, please follow these Bioconductor composing guidelines when asking for help. 3.1.1 Avoid screenshots While a screenshot might convey a lot of information, it is challenging to extract the relevant code in order to reproduce the error being described. Thus text is strongly encouraged over screenshots. 3.1.2 Reproducible code The function call and the associated error message are frequently not informative enough for others to determine the root of the problem. You should aim to include the traceback() information in R or equivalent in other languages which provides more detail on what happened. However, even the traceback() information might not be enough, which is why you should definitely include the code for re-creating any objects you used in the function call. One simple way to do so is to include a permalink to a script you have version controlled on GitHub. 3.1.3 Use reprex Use the reprex package for making small reproducible examples. Check our LIBD rstats club session on reprex to learn more about it. 3.1.4 Use Markdown syntax Either on Slack or GitHub, you can use some Markdown syntax features. In particular, you can use in line code formatting (1 back tick) and multi-line code formatting (3 backt icks). On GitHub, you can also use the html code tags &lt;details&gt; and &lt;/details&gt; to hide long output, which is useful for showing the R session information. That is, the output from sessioninfo. As an example, check this BayesSpace issue. 3.1.5 R session information Use the sessioninfo package to provide the full details of your R session. Some errors might have already been addressed in newer versions of R packages or R versions. Providing that information makes it easier for others to help you. 3.2 Learning from our search history We have occasionally used a team activity called “learning from our search history” described in this blog post. One of the goals of this activity was to learn some search skills each of us has that are typically not taught. Another goal was to show that we all search for more information all the time because no one, not matter how experienced, knows all the answers. 3.3 Bioconductor Support website We use Bioconductor R packages for most of our work because they contain a lot of useful functions for the type of work we do. Bioconductor packages can be under active development and changing frequently. Plus, some are challenging to understand how to use. For these and other reasons, Bioconductor has a BioC Support Website. You will need to make an account before you can ask (or answer) a question. Once you do, you will need to use tags for labeling your question: typically with the tag that matches the Bioconductor package you are using. When you start to ask a new question, you will see a link to the new posts guide and the tutorial for asking questions. You should try your best to follow those guidelines in order to make it easier for others to help you. Remember that you should follow the Bioconductor code of conduct. 3.4 RStudio Community website Since we use R so much, we also use R packages developed by RStudio developers. One great and friendly website for asking for help with all things that are related to R (but maybe not so much related to Bioconductor) is the RStudio Community website. This website is particularly useful if you have questions about RStudio itself or the tidyverse R packages. If you want to get a summary of new posts that might be relevant to you, you can sign up for weekly email updates. On this website, there’s a strong preference for using the reprex package for making small reproducible examples. Check our LIBD rstats club session on reprex to learn more about it. 3.5 GitHub Frequently, we work with software that is cutting edge and under active development. Many people share their code through websites like Bitbucket, GitLab, and most frequently, through GitHub. At LIBD we have a GitHub organization account github.com/LieberInstitute. Think of it as our code library. As described in more detail in this video, you can search our code base, which might be useful to see actual examples on how we’ve used functions from specific R packages or other tools. If you work at LIBD, email Bill Urich so he can add you to the organization account, thank you! 3.6 GitHub issues Most open source projects on GitHub have an issues page where you can interact directly with the developers of the software you are using. Note that most open source software developers are not payed to provide support, and their time might be very limited. As such, you should try very hard to provide all the information the developers need in order to help you. This is a time consuming process, but it can help you learn more too, and sometimes even resolve the problem yourself. Some GitHub repositories have issue templates such as lcolladotor/biocthis that will tell you a bit more of what information you should provide to make it easier for others to help you out. Others like rstudio/blogdown will ask you to fill a few checkmarks before submitting your question. Again, Jim Hester has some useful advice. Writing issues with too much description is nearly as bad as too little. 𐄷Often the real problem is something completely different then what the reporter spent so long describing. 🤔One reproducible example is worth 1,000 words. 🖼 — Jim Hester (@jimhester_) January 15, 2021 3.7 Mailing lists Eventually, you might need to ask for help through specific e-mail mailing lists. This is more common the closer you get to source code. Some of the mailing lists we use frequently are listed below. 3.7.1 JHPCE If you need help with R and JHPCE, you might find this video and companion notes useful. 3.7.1.1 bithelp This is the main mailing list for asking for help with all things related to JHPCE. The JHPCE admins plus some JHPCE users such as myself and Kasper Daniel Hansen receive these emails and might reply back. You can sign up to receive these emails too if you want. Or if you want to check the previous emails, check the bithelp website. Before you ask for help, check the JHPCE website since there are several guides there already that might answer the question you have in mind. 3.7.1.2 bitsupport This is the main mailing list for all things related to JHPCE admin requests. For example, if you need help with getting your password reset or changing your default JHPCE user group. 3.7.2 Bioc-devel This is the mailing list where all Bioconductor package authors are subscribed to. It’s sole purpose is to help current and new Bioconductor package authors. If you have questions about how to use a Bioconductor R package, use the Bioconductor Support website only. However, if you do have questions about R package development, then check out bioc-devel and its archives. You might also like this video on some specific feedback about R/Bioconductor package development. Here are some companion notes. If you are getting started with R/Bioconductor package development, then this video explaining biocthis might be useful as well. Here are the slides. 3.7.3 R-Sig-Mac Some mailing lists are very specific to what they serve. There are several of these mailing lists related to the R source itself, for sample R-SIG-Mac which is useful if you are compiling R in macOS, and only for questions related to that. This is a rare situation for us, but for some situations, this is where you can find the latest information and reach the experts on this topic. 3.8 Slack Within our team and collaborators, we use Slack extensively. If you are new to Slack, you might want to read this blog post that I co-authored with Stephanie C Hicks. In that blog post, we talk about some important Slack settings that will make it easier to keep your work-life balance in check. Slack is organized in Workspaces. Each of them is either free or payed, depending on the group. We mostly use the JHU Genomics Collective Slack workspace, which is a payed workspace. Meaning that we have access to all Slack-related goodies, like integrations with GitHub, Google Calendar, Google Docs, email, etc. Below you can find more information about the differnet Slack workspaces we use. 3.8.1 JHU/LIBD 3.8.1.1 JHU Genomics Collective This is our main Slack workspace. Just like git commit messages, channels are cheap. The idea is to make one channel per project. Currently, we are adding all team members to each channel even if they are not working on the specific project. Team members not involved in the project should feel free to mute the channel. However, by being a part of the channel, they can then see images and code that we are working on, which in some situations can be useful. For example, maybe we figured out how to make a new plotly interactive graph in one channel, then others who are curious can get access to that knowledge and incorporate it into their projects. If you need help use: libd_helpdesk: for asking general questions to all team members and LIBD collaborators For team logistics, our channel is: libd_team_lcolladotor: meeting reminders, papers we’ll discuss and other team logistics The remaining main Slack channels are: libd_alumni: for all LIBD past and current members libd_dsgs: for the DSgs-guides libd_general: for all current LIBD members that are on the JHU Genomics Slack workspace libd_genomics_martinowich: a shared channel with the Martinowich lab Slack workspace libd_lunchtrain: for random topics as well as organizing lunch outings 7 using the /lunchtrain Slack command 8 libd_pkgs: for software (mostly R packages) we are making that is not specific to a particular project libd_rstats_club: for the LIBD rstats club There are also a set of public channels that we use frequently: conferences containers: docker, singularity, etc diversity funding general genomics_journal_club: a student-run journal club genomics_seminar: Genomics at JHU seminars jhpce: JHPCE users, though also check the bithelp and bitsupport mailing lists jhu_papers: where we announce papers with JHU authors joint_group_meeting: a JHU bi-weekly meeting led by Steven Salzberg and JHU colleagues. This is a great meeting to learn about methods work being done across Hopkins for genomics data analysis. langmead_rss: a channel where Ben Langmead shares papers he’s interested in r-ladies random rstats: major R announcements and other goodies 3.8.1.2 Martinowich This is the LIBD Slack workspace used by Keri Martinowich’s team. Several of us work closely with her, Kristen Maynard, Stephanie Page and other Martinowich team projects. Some Slack channels of interest here are: comm_labmeeting: for any communications related to the Martinowich lab meeting helpdesk_general_drybench: a channel that was inspired by libd_helpdesk on the JHU Genomics Slack helpdesk_figuregeneration_and_manuscriptwriting: it says it all in the name ;) 3.8.1.3 LIBD Neuropathology This is the LIBD Slack workspace used by the Neuropathology team. We use it to interact with Amy Deep-Soboslay, Ran Tao, and their teams. 3.8.2 Bioconductor One very useful public Slack workspace is the Bioconductor one. You can join for free through bioc-community.herokuapp.com/. If you join this Slack workspace, please introduce yourself on the introductions channel. You mgith also be interested in channels such as: biocYYYY where YYYY is the given year, which is the main channel for that year’s Bioconductor conference. For example, bioc2020. containers to learn more about the Bioconductor Docker images developers_forum for learning about the Bioconductor Developer’s forum (typically held once per month) jobs for job announcements spatial for spatial transcriptomics and related technologies 3.8.3 R-Ladies Baltimore Another public Slack workspace is the one run by R-Ladies Baltimore, a local chapter from R-Ladies Global. This Slack workspace is mostly active during the meetup sessions. Check out their Meetup page for more information. 3.8.4 Miscellaneous I’m a part of a few more Slack workspaces, though not all of them are public. JHU Biostatistics: for members and alumni of the JHBSPH Biostatistics department. rOpenSci: for members of rOpenSci CSCCE: from the Center for Scientific Collaboration and Community Engagement which is useful if you want to learn more about community engagement CDSB: the Community of Bioinformatics Software Developers (in Spanish) which I co-founded in 2018 and through which we organize R workshops to help grow the community of R/Bioconductor developers in Latin America LatinR: a public Slack workspace related to the LatinR conference and community, whose goals are overlaping with those from CDSB Or remote lunch Zoom sessions.↩︎ Start typing the command on Slack and you’ll see the help menu pop up for this command which specifies the syntax for using /lunchtrain.↩︎ "],["rbioconductor-data-science-bootcamps.html", "4 R/Bioconductor Data Science bootcamps 4.1 Overview videos 4.2 LIBD bootcamps 4.3 Team bootcamps 4.4 Bootcamp source materials", " 4 R/Bioconductor Data Science bootcamps In order to have a common set of external references and R knowledge that we use for the Data Science guidance sessions as well as our work, we have a series of R and Bioconductor bootcamps. Most of the material these bootcamps are based on is freely available or can be purchased for a small fee 9. Thus, we can feel confident that our LIBD and JHU collaborators will be able to access the material, as well as anyone else in the world. You can also find the videos of all our bootcamps on YouTube at lcolladotor/playlists and described on the following Twitter thread. It's been ~4 weeks. We spent the first 3 learning more about #rstats #bioinformatics &amp; @Bioconductor. If you are interested in our bootcamp sessions, you can find the videos at https://t.co/uBVqZMfgkPand in general athttps://t.co/JjZMQZsY1S@LieberInstitute @LIBDrstats ✌️🏽 https://t.co/uujaBguHMi — 🇲🇽 Leonardo Collado-Torres (@lcolladotor) October 16, 2020 Here are the videos from YouTube. 4.1 Overview videos Here are some highlighted overview videos that you might find useful as you get started. 4.1.1 R and RStudio If you are new to R and RStudio, you might like this overview video and companion notes. 4.1.2 Bioconductor Similarly, this overview video and companion notes on Bioconductor might be useful too. 4.1.3 ggplot2 R graphics This video and companion notes on ggplot2 R graphics could also be useful. 4.1.4 Submitting jobs at JHPCE This video on how to use sgejobs for submitting jobs at JHPCE could be useful too. For a more advanced video on setting up bash loops and nested qsubs, check this second sgejobs video. If you need to use the GPU queue at JHPCE, then check this video and companion slides. 4.2 LIBD bootcamps We have organized accessible bootcamps that have biologists in mind. If you spend most of your time coding, check the Team bootcamps further below. For all of these bootcamps, you should have the latest R and RStudio Desktop installed. You will typically need a computer with at least 8 GB of RAM. Session Time Prerequisites Topic 1 2020-10-05 3-5 pm R + RStudio Differential expression analysis (LIBD-style) 2 2020-10-06 3-5 pm R + RStudio Differential expression analysis (LIBD-style) 3 2020-10-07 1-3 pm R + RStudio Differential expression analysis (LIBD-style) 4.3 Team bootcamps The team bootcamps are really for our team members and other more advanced R/programming members and collaborators. However, the material we cover is within reach of everyone as long as you practice using R/Bioconductor here and there. The concepts covered are of use to all of us who work with R, but we understand that you might not have as much time to learn these materials. If that’s the case, please feel free to sign up for our Data Science guidance sessions and we’ll help you learn these concepts at your own pace. The first iteration of these bootcamps were run on September 2020 with the following schedule. For all of them, you should have the latest R and RStudio versions installed in your computer and be familiar with the R programming language. For a more structured working environment, we might use JHPCE’s computational resources while running RStudio on our computers and running code through a Linux terminal 10. You will probably need to spend time self-learning and practicing some of the material beyond these videos. If you just started learning about R, then these bootcamps will be quite challenging. Session Time Prerequisites Topic 1 2020-09-21 3-5 pm NA How to be a modern scientist 2 2020-09-22 3-5 pm R + RStudio What they forgot to teach you about R 3 2020-09-23 1-3 pm R + RStudio What they forgot to teach you about R 4 2020-09-24 3-5 pm R + RStudio The Elements of Data Analytic Style + CBDS 5 2020-09-28 3-5 pm R + RStudio The Elements of Data Analytic Style + CBDS 6 2020-09-29 3-5 pm Be a part of the DSgs-guides team DSgs-guide training 7 2020-09-30 1-3 pm RStudio + R functions Building Tidy Tools 8 2020-10-01 3-5 pm RStudio + R functions Building Tidy Tools 4.4 Bootcamp source materials There are tons of resources that are useful for learning about R, Bioconductor, and data science in general. We have selected some of those resources because: we are familiar with them they are freely available or can be purchased for a small fee we have heard good things about them 4.4.1 Main materials There are more materials out there than those that we’ve had a chance to learn about, and with time, this list will change. Here is our latest list. Introductory level course Cloud Based Data Science by Jeff Leek, Aboozar Hadavand, Shannon Ellis, Leslie Myint, Sarah McClymont, Leah Jager, and others. Advanced book R for Data Science by Garrett Grolemund and Hadley Wickham. Useful for learning about the tidyverse, which is supported by RStudio. workshop What they forgot to teach you about R 2020 version by Kara Woo, Jenny Bryan, and Jim Hester. workshop Building Tidy Tools 2020 version by Charlotte Wickham and Hadley Wickham. General book The Elements of Data Analytic Style by Jeff Leek. book How to be a modern scientist by Jeff Leek. book The Art of Data Science by Roger D. Peng and Elizabeth Matsui. Statistics book Data Analysis for the Life Sciences by Rafael A Irizarry and Michael I Love. book Modern Statistics for Modern Biology by Susan Holmes and Wolfgang Huber. Bioconductor book Orchestrating Single-Cell Analysis with Bioconductor by Aaron Lun, Robert Amezquita, Stephanie Hicks, and Raphael Gottardo. workshop WEHI scRNA-seq course (2020) by Peter Hickey based on the OSCA book. workflows Bioconductor Common Workflows. There’s over 25 of them from many authors. We also highly recommend keeping an eye open for any new work from: Alison Presmanes Hill. Just look at her awesome projects website! Desirée De Leon. Note that Desirée started as an intern working with Alison, so it’s no surprise that her projects website is excellent. Allison Horst and in particular her stats-illustrations which are widely used and are very helpful when teaching statistical and R concepts. 4.4.2 Courses Our colleagues at Hopkins have also created Coursera courses (MOOCs) which you might be interested in, though they might involve other fees. These are: Genomic Data Science Specialization by Steven Salzberg, Jeff Leek, James Taylor (1979-2020), Mihaela Pertea, Ben Langmead, Jacob Pritt, Liliana Florea, Kasper Daniel Hansen. Actually, LIBD is an “industry partner” for this specialization. Data Science Specialization by Jeff Leek, Roger D. Peng, and Brian Caffo. Data Science: Foundations using R Specialization by Jeff Leek, Roger D. Peng, and Brian Caffo. Executive Data Science Specialization by Jeff Leek, Roger D. Peng, and Brian Caffo. The Unix Workbench by Sean Kross, Jeff Leek, Roger D. Peng, and Brian Caffo. Rafael Irizarry and his lab have also generated free teaching materials. A former postdoc with Rafael, Michael I Love also has teaching materials. Between them they have courses on: Introduction to Data Science (at least 8 college-level courses) Data Analysis for the Life Sciences (at least 4 graduate level courses) Genomics Data Analysis (at least 3 graduate level courses) They have lots of YouTube links organized on their old harvardx website, whose layout is based on Kasper Daniel Hansen’s Bioconductor for Genomic Data Science course. A lot of the resources listed are available through Leanpub which is a publishing platform for books and courses. Authors get to set a recommended price, but also a minimum price that can be as low as $0, thus making their materials free to use.↩︎ Check our LIBD rstats club videos on how to configure your macOS or Windows computer to work with JHPCE.↩︎ "],["how-to-be-a-modern-scientist.html", "5 How to be a modern scientist 5.1 Bootcamp session", " 5 How to be a modern scientist Jeff Leek wrote a book called How to be a modern scientist that is available through Leanpub. This book compiled and re-arranged advice and ideas Jeff generated in the prior years and shared through the Simply Statistics blog. While the book is written with academics in mind, particularly graduate students and postdocs, nearly all of the advice in this book applies to us as well. We actively participate in writing academic papers and software, and we work very closely with graduate students and postdocs. We might even advise some through our Data Science guidance sessions. Hence being familiar with this knowledge that Jeff curated and developed is important for us. In the book, Jeff explains why something is important and also provides specific advice on tools he liked to use (in 2016) for implementing these ideas. Most chapters can be read independently, with “paper writing” directly linked to “reading scientific papers”. After reading the introduction, choose whichever chapter appeals to you the most in the moment. For some of the chapters, we have more specific information on this book such as: reading scientific papers and scientific talks are something we practice weekly on the Team meetings career planning was the basis for Career growth The full list of chapters is: Introduction Paper writing Publishing Peer review Data sharing Scientific blogging Scientific code Social media in science Teaching in science Books Internal scientific communication Scientific talks Reading scientific papers Credit Career planning Your online identity About the author We do everything in this book, though to different degrees. This book is actually a key part of our internal scientific communication. I’ve also done several of the things Jeff advises not to do ;) and maybe that’s why they are listed there hehe. Hopefully I’ve learned over the years though. 5.1 Bootcamp session Below you can watch the video of our training session. For more information about Jeff’s Leanpub materials, check this link. "],["what-they-forgot-to-teach-you-about-r.html", "6 What they forgot to teach you about R 6.1 Bootcamp sessions", " 6 What they forgot to teach you about R Jenny Bryan, Jim Hester, Kara Woo and others have spent a significant amount of effort thinking about organizing R projects and developing tools that facilitate this process. They have written papers describing their ideas, trained others on how to implement their ideas through workshops, and written free books. Two of the main books related to these ideas are: What They Forgot to Teach You About R Happy Git and GitHub for the useR In these books, they teach how to use R, RStudio, git/GitHub, and overall how to organize your code and projects. As I’m writing this, their most recent workshop was at rstudio::conf(2020) which is publicly available through rstudio-conf-2020.github.io. 6.1 Bootcamp sessions Using the what they forgot (WTF) rstudio::conf(2020) materials, we spent two bootcamps sessions (each 2 hours long) learning these ideas and examining how they can help us for our work. We aim to implement the organization principles in our work because of the value they bring and to have a common baseline. We will teach others these concepts more slowly through Data Science guidance sessions. Below you can watch the videos of our training sessions. "],["the-elements-of-data-analytic-style.html", "7 The Elements of Data Analytic Style 7.1 Bootcamp session", " 7 The Elements of Data Analytic Style Jeff Leek is world renowned for his efforts in data science education and become widely known through the JHU Data Science Specialization Coursera courses as well as the Simply Statitics blog. Over the years, Jeff has shared his ideas through multiple venues including GitHub repositories such as jtleek/reviews which provides a guide for reviewing papers. Around 2016, Jeff re-organized his ideas related to learning and applying data science to create a book called The Elements of Data Analytic Style that you can buy for a small amount or even get it free through Leanpub. This book is about 90 pages long and is organized in chapters that cover topics such as: The data analytic question Tidying the data Checking the data Exploratory analysis Statistical modeling and inference Prediction and machine learning Causality Written analyses Creating figures Presenting data Reproducibility A few matters of form The data analysis checklist 7.1 Bootcamp session We spent one of our bootcamp sessions going over this book and getting familiarized with some Jeff’s ideas as well as identifying sections that we can refer others to during our Data Science guidance sessions. Below you can watch the video of our training session. For more information about Jeff’s Leanpub materials, check this link. "],["cbds.html", "8 CBDS 8.1 Bootcamp session", " 8 CBDS Jeff Leek and others educated thousands of people through the JHU Data Science Specialization Coursera, yet they noticed that the audience signing up for those courses was dominated with individuals that had access to undergrad and graduate education already. To help people who didn’t have those opportunities but who would still benefit from learning data science skills and R, Jeff put together a team including Aboozar Hadavand, Shannon E Ellis, and many others listed at Leanpub and on the CDSB website 11. This team developed Cloud-Based Data Science (CBDS) as well as CBDS+. CBDS is a collection of Leanpub courses, each of them composed of several lessons and quizzes. Each lesson is described in text and slides, but the material is also available as videos. The videos were made using the R package ari by Sean Kross, processing software written by John Muschelli, and a dictionary detailing how to pronounce data science terms made by Sarah McClymont. The Leanpub courses are available here, which can be purchased for a modest fee or even for free. These courses were designed to be accessible by anyone as young as high school graduates. The hardware requirements are as minimum as possible, meaning that they can be taken using a Chromebook and using cloud resources. That is why these courses are the main ones we recommend for new R users. However, don’t be tricked into thinking that they don’t teach you important skills. For example, there is a full course on how to use git/GitHub that is crucial to our work and that is taught at the end in some other courses. That is, CBDS explains all the practical tools and skills that you will likely need. 8.1 Bootcamp session To get ourselves familiarized with CBDS and the courses provided by it, we spent one of our 2 hour bootcamp sessions learning about CBDS. Below you can watch the video of our training session. For more information about Jeff’s Leanpub materials, check this link. If you are interested in Data Science education, you should seriously consider joining this team! I can help you get in touch with Jeff if you want.↩︎ "],["building-tidy-tools.html", "9 Building Tidy Tools 9.1 Bootcamp sessions", " 9 Building Tidy Tools In order to organize our code, test it, and share it internally and also externally, we write R packages. Some of them we submit them to Bioconductor and share them more widely. There are several R packages that make the process of writing new R packages easier, such as devtools, usethis, roxygen2, and biocthis. To learn more about devtools and friends, we revised the material from the rstudio::conf(2020) workshop Building Tidy Tools that was taught by Charlotte Wickham and Hadley Wickham. In the LIBD rstats club, we’ve also used materials from their 2019 workshop. Today with @lcolladotor we finished ✅ learning about #purrr 🐈, functional programming and basics of #rstats functions using @CVWickham's slides 🤩 from #rstudioconf 2019📹https://t.co/X21qSQT8oX📔 https://t.co/sE849den78💻 https://t.co/ShN6JhGXXChttps://t.co/i6lmnrbBB5 — LIBD rstats club (@LIBDrstats) August 14, 2020 The Building Tidy Tools workshop is very useful if you want to transition from R user to R developer. If you are a Spanish speaker, you might be interested in our translation of their rstudio::conf(2019) workshop at CDBS. 9.1 Bootcamp sessions This workshop involves several exercises, which we highly recommend that you try to solve. One of our solutions is lahuuki/foofactors2. Below you can watch the videos of our training sessions. "],["differential-expression-analysis.html", "10 Differential expression analysis 10.1 Bootcamp sessions", " 10 Differential expression analysis To learn about differential expression analysis we used the data from the SPEAQeasy-example website we made. This involves work mostly by Nicholas J. Eagles, Joshua M. Stolz, and Louise A. Huuki-Myers. In particular, we followed the set of activities described in detail at SPEAQeasy-example/bootcamp_intro. There are several Bioconductor workflows that also explain how to do differential expression analyses. However, we used the data from SPEAQeasy-example because it has specific properties that are common to the processed data we generate at LIBD, given that we’ve processed a lot of RNA-seq data using SPEAQeasy. Having said that, for more in depth explanations, you might want to check the RNAseq123 and the rnaseqGene Bioconductor workflows that explain how to use packages such as limma and DESeq2. 10.1 Bootcamp sessions Below you can watch the videos of our training sessions. "],["team-meetings.html", "11 Team meetings 11.1 Papers &amp; software 11.2 DSgs: feedback 11.3 Team help 11.4 Individual updates 11.5 Project meetings", " 11 Team meetings Every week we meet for about an hour. The team meeting has three sections: [30 min] Papers &amp; software: we discuss either a paper or some software. The discussion is lead by a team member and the presentation is made public on YouTube while the discussion is kept private. [10 min] Data Science guidance sessions: we talk about our sessions and provide internal feedback. [20 min] Help requests: we give open the floor to discuss anything we need help on from the rest of the team. If you have a topic in mind, add it to the team meeting calendar. On some occasions we have meetings fully dedicated to: A paper or software A practice presentation by one of our team members in order to build up and polish our presentation skills. These are typically held during the Summer or prior to specific conferences/LIBD seminars. Code written by one of our team members: show us something you’ve been working on, something you want feedback on, etc. Think of it as a group-level paired coding session. 11.1 Papers &amp; software Each week, we rotate team members as shown on this presenters Google Spreadsheet. That team member is in charge of: finding a paper or a software of interest notifying the group about it at least one week ahead on Slack using the @channel tag on the libd_team_lcolladotor Slack channel preparing a few slides to explain the main concepts to us (plan for a 15 minute presentation) add some quick notes or short summary on the Google Spreadsheet The rest of the team members are responsible for reading the main PDF of the paper or software. Optionally, members can read the supplementary material, check the GitHub repository(ies) associated with the paper, or public peer reviews (some journals make them public). If the paper was recorded on the presenters Google Spreadsheet at least a week in advance, then team members are expected to have read the paper regardless of whether the presenter sent a reminder Slack message or not. Overall, all team members have to contribute and be engaged in our continuous learning activities. It is likely useful for everyone to register on Google Sheets for automatic updates 12 from the the presenters Google Spreadsheet. We record that portion of our meeting and make it publicly available through the presenters Google Spreadsheet. We then discuss privately our thoughts on the paper or software. Here’s our first video: You can also find the rest of them under the team lcolladotor YouTube playlist at lcolladotor/playlists. 11.1.1 Notes If you are randomly assigned a date that does not work for you, please get in touch with other team members and find someone who can switch with you. Thank you! If you are interested in joining us, please check our code of conduct, and get in touch with Leonardo. 11.2 DSgs: feedback Every week, the DSgs-guides meet to discuss recent guidance sessions with the following objectives: identify common topics that can be addressed in other venues such as the LIBD rstats club, this book, blog posts, etc ensure consistency of our responses to similar questions identify and address issues with our DSgs interaction rules We might identify topics that we need to either train the DSgs-guides on or our LIBD/JHU colleagues, as well as useful R functions/packages that we can write to help us and others. 11.2.1 Notes You don’t have to be a part of Leonardo’s team to be a DSgs-guide and thus join this meeting. 11.3 Team help While each team member has an individual weekly meeting, sometimes some problems can be solved with other/fresh eyes looking at them as well as new ideas. If you are having one such problem, this is a great venue to get help for it. This space and time can also be used for asking some quick questions as well as addressing any administration announcements. 11.4 Individual updates On Mondays at 10:30 am everyone meets with Leo sequentially for 30 min to discuss individual updates. These meetings are useful to talk about what projects take priority on a given week, personal issues, and personal career development decisions such as which conference(s) to attend. Here’s a list of conferences/courses of interest. 11.5 Project meetings Here’s the list of project meetings and who should attend them: Tuesday Moods: Louise, Leo. Optional: Geo. Habenula + multi-ome + Fentanyl: Bukola, Cynthia, Daianna, Louise, Renee, Leo. Optional: Hédia, Nick. Wednesday team meeting: everyone. Thursday: spatial team meeting: Louise, Nick, Leo. deconvolution: Louise, Leo. NAc spatial: Nick, Leo. Friday LIBD rstats club: everyone. Unassigned CHESS-BRAIN: Geo, Hédia, Leo. I recommend a daily digest instead of an email per update.↩︎ "],["helping-others.html", "12 Helping others 12.1 Linear regression example 12.2 DSgs guides 12.3 Bioconductor Support: practice grounds 12.4 RStudio Education", " 12 Helping others Part of our job is helping others understand what we are doing. In my experience, we can use three different communication languages and different combinations of them are useful by others, given that everyone is different. These languages are: written text/words drawings and graphs math equations 12.1 Linear regression example For example, if we have a linear regression \\[ Y = \\beta_0 + \\beta_1 X + \\epsilon \\] with \\[ \\epsilon \\sim N(0, \\sigma^2) \\] and we want to explain the meaning of the coefficient \\(\\beta_1\\) then we can explain it as: Text: \\(\\beta_1\\) is the average change in our outcome \\(Y\\) for a one unit increase in our explanatory variable \\(X\\) The language here is quite precise and it can be hard to understand the implications of every word. This is the typical starting point for many questions: what does this mean? Drawings: image source We have three data points (\\(x_1\\), \\(y_1\\)), (\\(x_2\\), \\(y_2\\)) and (\\(x_3\\), \\(y_3\\)) and we draw a line that shows the relationship between our \\(X\\) and \\(Y\\) variables (each on its own axis). This line that we have drawn (shown in red) has two components that can be summarized by a small triangle (shown in green). The triangle has one vertex that touches the Y axis, this is the intercept, also known as \\(\\beta_0\\). Then it has a side of length 1 on the x-axis, and \\(\\beta_1\\) is length of the vertical side of the triangle that starts at \\(Y = \\beta_0\\) and ends at our diagonal line. That is, \\(\\beta_1\\) is the height of the green triangle when the length is equal to 1 on the x-axis. This visual representation can be useful for understanding the words we started off with. Math: First, notice that our linear model is \\(E[Y] = \\beta_0 + \\beta_1 X\\), then we provide two values for \\(X\\): little \\(x\\) and little \\(x\\) plus one, and compute the difference between them. That leads to the following equations (show further below). It can be very useful here to explain how the math on that first equation translates to the written text we started off with. \\[ E [Y | X = x + 1] - E[Y | X = x] \\] \\[ = ( \\beta_0 + \\beta_1 (x + 1) ) - (\\beta_0 + \\beta_1 x ) \\] \\[ = \\beta_0 + \\beta_1 x + \\beta_1 - \\beta_0 - \\beta_1 x \\] \\[ = (\\beta_0 - \\beta_0) + (\\beta_1 x - \\beta_1 x) + \\beta_1 \\] \\[ = \\beta_1 \\] @lcolladotor adopts old-school tools during a virtual workshop on SPEAQeasy to explain how to identify RNA- DNA sample swaps. #EuroBioc2020 workshops, slides are available from https://t.co/bh3Afbub70@Bioconductor #rstats pic.twitter.com/dtqsfImOTz — Aedin Culhane (@AedinCulhane) December 17, 2020 12.2 DSgs guides As DSgs-guides for the Data Science guidance sessions (DSgs), our role involves: Explaining a concept creatively. For example, the person asking the question might have been confused by a lecture or the documentation of a function, and we have to explain those written words using a combination of: other words, drawings, and/or math 13 Google searching. We might be more familiar with some useful keywords that can lead us to a more precise answer, or given our experience we might be able to tease apart faster possible answers from say a help forum to identify the answer that best matches our scenario. Providing ideas. If some code is not working, we can provide ideas on how to troubleshoot that problem as well as identify potential key components of an error message. For a given analysis path, we can also provide options on what routes to take including potential useful graphs to create. Baseline platform. We can help others get used to our baseline platform of tools we use. Hence why we go through the bootcamps to have a common knowledgebase and set of courses, workshops and books that we refer others to. We can also be a bouncing board for others to discuss their ideas, and sometimes help with our feedback. 12.2.1 DSgs-guide training Accomplishing our role as DSgs-guides can be a bit scary since others will expect us to know the answers to many different questions. They might also be under intense pressure and might try to offload some of that pressure on to us. In other words, human interactions are complex. To deal with this, we have defined a set of Interaction rules to protect us. But we also need some training. First of all, remember that it’s OK to not know the answer. Simply communicate that you don’t know the answer instead of trying to hide it. You can then: search for an answer prior to your next DSgs session with the person asking the question bring that question up during our DSgs: feedback weekly session request that someone else take over the question 14 Remember that some questions are very challenging! After all, at LIBD we are trying to answer complicated biological questions that no one has an answer to. During my time as a Teaching Assistant at JHBSPH: Biostatistics, we had an activity called the Teaching Assistant Training Day, which I have adapted for our purpose. This involves: Being a DSgs-guide Classify characteristics I recommend also reading the following papers: Irwin D. J. Bross (1974) The Role of the Statistician: Scientist or Shoe Clerk, The American Statistician, 28:4, 126-127, DOI: 10.1080/00031305.1974.10479092 Lurie, William. “THE IMPERTINENT QUESTIONER: THE SCIENTIST’S GUIDE TO THE STATISTICIAN’S MIND.” American Scientist, vol. 46, no. 1, 1958, pp. 57–61. JSTOR, jstor.org/stable/27827055. Finney, D.J. (1982), The questioning statistician. Statist. Med., 1: 5-13. doi: 10.1002/sim.4780010103 Below you can watch the video of our training session. 12.2.2 Common responses 12.2.3 Internal sessions log In order to make our job easier the next time we get a similar question, we have an internal sessions log where we record: the question we got asked the links we referred anyone to or that we used during the session example code we used This log also helps us refresh our memory so we can remember what are the links we’ve told someone else to use and see their trajectory. The sessions log also enables DSgs-guides to learn from each other. The internal sessions log is then used to populate the content of the DSgs_logs website. It’s best to fill out an entry on the sessions log immediately after a session. That way your memory is fresh. That’s why we recommend planning for 10 minutes after a session to fill out your entry in the log and to send a message with the links from the session to the person who requested it 15 12.2.4 Getting started If you just joined the DSgs-guides team, then we need you to setup your Calendly account and provide a brief description of who you are and what you are interested in helping others with. 12.2.4.1 Calendly Calendly is a service that allows others to sign up for meetings with you. The free service lets you connect it with a single calendar, say your LIBD calendar 16. With the free account you can then specify a type of event which you can use to create a 25 min data science guidance session event like mine: Calendly event description Meet with Leonardo for a 25 minute session where he’ll try his best to guide you in your data science project or related question. Please provide information in advance that might be useful for preparing for this session based on https://lcolladotor.github.io/bioc_team_ds/data-science-guidance-sessions.html#help-us-help-you. Thank you! I customized my event with: duration: 25 min date range: over a period of rolling days; 6 business days availability increments: 15 min minimum scheduling notice: 24 hrs 17 event buffers: before (5 min), after (10 min) To control the number of sessions per week, I only opened my availability for 4 days of the week 18 and specified 1 for the “event max per day” advanced setting 19. Choose your settings wisely such that you can avoid as much as possible having to reschedule meetings for others, that is, be careful with the expectations you create in others. Once you are done, we’ll need your public Calendly event link to add it to the DSgs sign up page. 12.2.4.2 Description We need a short description of who you are and what type of questions you are interested in helping others with. Since you’ll be learning while you help others, you might want to specify areas that you are actively learning more about. Below is a small template, but you might simply want to check the DSgs sign up page. * [YOUR NAME](https://github.com/YOUR-USERNAME) ([BioC Support](https://support.bioconductor.org/u/YOUR_PROFILE_NUMBER/)) - Research interests: xx, yy, zz. - Technologies I use: aa, bb, cc. - Learning about: uu, ii, oo. - [Calendly](https://calendly.com/) 12.3 Bioconductor Support: practice grounds We use Bioconductor R packages basically every day for our work and the main venue for asking for help related to Bioconductor is the Bioconductor Support website as mentioned in a previous chapter. A great way to learn is by helping others. So, DSgs-guides should try to help one person per week on the Bioconductor Support website. By doing so, they’ll learn more about Bioconductor, practice helping others, and also learn what information helpers need. Then, the next time the guides ask questions themselves, they’ll know what information they need to provide in order to help others help them. 12.3.1 Steps to follow To keep track of who we have helped please fill add an entry to the following Google Sheet. Briefly, you need to: find a question you are interested in answering decide whether to reply as a comment or answer remember to be friendly 20 The Bioconductor Support website uses a “tags” mechanism where each tag is actually the name of a package in lower case. So, when you are searching for questions to answer, you might want to start with the tag for a package that you are interested in learning more about or that you are interested in. You might also want to look at the latest questions and maybe start with those that have no answers. Some questions are quite common, like issues with installing Bioconductor packages, so in a way, that could be a low hanging fruit. Note that you can also edit your profile and add watched tags which you can check on the top menu under “following”. Once you have chosen an interesting question, you can either write an answer or a comment. Comments are useful when you need more information from the person asking the question. For example, you might need them to provide their R session information, which will help you figure out what version of R and Bioconductor they are using 21. Comments and answers support Markdown replies, which can be quite helpful for formatting your answer 22. Here’s a template you can start using. Hi xx, ~~ answer ~~ Best, YOUR-NAME PS I&#39;m actively [learning how to help others](https://lcolladotor.github.io/bioc_team_ds/helping-others.html#bioconductor-support-practice-grounds), so please be patient with me. Thanks! ## R session information `sessioninfo::session_info()` output Remember that questions can have multiple answers, so other Bioconductor Community members might contribute their solutions, which is a great way to learn. Also, we are doing this as volunteers really, so if a question gets complicated, it’s OK to notify the person who asked it that you don’t have the time to help them further. 12.4 RStudio Education If you want to go even further, you might be interested in the RStudio Education: learn to teach website. Use the Remember to use the main materials, such as the illustrations by Allison Horst, to avoid having to reinvent the wheel and for quick access to great illustrations. ↩︎ Then study their answer from our sessions log, so that way you learn too and increase your personal knowledgebase.↩︎ You might want to have a template email where you can just copy the same links and code from the session into it.↩︎ Though I use my LIBD and my Gmail calendars and thus need to pay for Calendly’s more advanced features.↩︎ You want to have enough time to check the question someone asked and come prepared to the DSgs session.↩︎ You can choose what hours of the day you make yourself available to others.↩︎ I’m not 100% sure that this works on the free account.↩︎ Sometimes people are unkind on the web or voice their frustrations. It’s hard not to take it personal at times, but try to remain as friendly as possible. Also, you don’t owe them anything and you should feel free to ignore unfriendly folks.↩︎ Many times, the solution is to upgrade to the latest Bioc-release version.↩︎ There is a limit in length, which is why I sometimes use public gists on my replies. Gists are automatically embedded in answers. This is useful if you want to include a long output from your own sessioninfo::session_info().↩︎ "],["project-feedback.html", "13 Project feedback 13.1 Slack 13.2 Meetings 13.3 Code review", " 13 Project feedback In the team anonymous survey from 2021-03 several responses revealed a need to provide more structure for project feedback. This chapter attempts to clarify what you can do to get feedback. 13.1 Slack As specified at How to ask for help, we have several Slack channels that you can use to ask for help. This includes asking clarifying questions about concepts, acronyms, software, or terms that might be new to you. Please use these help channels to your own benefit. Furthermore, each project will have a Slack channel. There will also be a GitHub project that will sync updates automatically to the Slack project channel. You should use the project Slack channel to document your progress and ask questions instead of direct messages (DMs). If you use the project channel, other people can jump in and answer your questions. Furthermore, it enables me to see how the communication among team members is evolving and identify if the are misunderstandings I can clarify or identify if there’s a need to schedule a meeting or ask someone else to explain some concepts. Just like asking questions by email instead of public forums is heavily discouraged at how to ask for help, asking questions on DMs is heavily discouraged over asking questions on channels. DMs among project members are also heavily discouraged. Having said that, it’s ok to ask personal questions on DMs such as “can I take XX day off?” or to use DMs among project members for things like “hey, can we change our meeting from 1pm to 2pm today?”. Remember to follow the code of conduct to make sure everyone feels welcome and safe to participate in our Slack channels. Overall, we are doing team science which involves many areas of expertise. I don’t have the answers to all the questions, so there’s no point in funneling all questions through me via DMs. We have many colleagues who are also eager to interact with you, either at LIBD, JHU or beyond! ^^ It is highly recommended that if you have a question about a particular plot or result you generated, that you include the GitHub permalink to the plot/table/result 23 as well as the permalink to the code you used to generate such plot or result. When working on a project, you should aim to have at least 5 GitHub commits per coding session (roughly a 2-3 hours). Smaller commits are encouraged, specially if you are getting stuck. Your commit messages will automatically be shown on Slack channel for the project and will make it easier to determine when someone needs help. GitHub commits also serve as a proxy for productivity and can provide more information that presenting results: showing a plot doesn’t show all the work that went into trying to make the plot, learning the tools required to make it, customizing it, etc. Some of you prefer to turn on Slack notifications (pings) for their main project channel(s). For channels that you are in but where you are not actively working on, feel free to mute the channel. We’ll tag you if necessary. 13.2 Meetings We have several weekly meetings where you can get feedback on your project. Some of them are 1 on 1, some of them are with other team members, some of them are with colleagues. Those meetings provide a baseline. However, you can also use Calendly to request 1 on 1 meetings with team members or myself. After any meeting, it can be quite beneficial for everyone involved to post a bullet point summary on the main project Slack channel. Doing so helps everyone keep track of the main action items as well as progress made along the way. Detailed action items could be made as GitHub issues on the main project repository. 13.3 Code review We have discussed having formal code reviews. My impression was that the team was in favor of having on demand code reviews instead of pre-scheduled code review sessions. I would love it if people asked each other to review their code through Calendly. I think that it be highly beneficial to explain your code to someone else. You might realize that some step is not well documented, or that your script could be split into two or more scripts, as well as identify potential code chunks that could become functions (or even packages). You could also find a potential bug or get feedback on how to do things differently. Prior to a code review session, you might want to standardize your code using styler and biocthis with code similar to this one or this one. We have the infrastructure setup, it’s just a matter of using it =) Unless it’s too large for version control on GitHub. In that case, include the JHPCE full path.↩︎ "],["organizing-your-work.html", "14 Organizing your work 14.1 JHPCE file organization 14.2 Project documentation 14.3 Setting JHPCE file permissions 14.4 Moving files across JHPCE disks", " 14 Organizing your work In the team anonymous survey from 2021-03 several responses revealed that as a team we have some work to do to be more organized at JHPCE / GitHub as well in documenting our work. This chapter attempts to clarify what you can do to get feedback. 14.1 JHPCE file organization 14.1.1 Background history As noted the the survey mentioned earlier, files at JHPCE could be organized better. We have multiple disks at JHPCE and for historical reasons, some projects live at locations such as /dcl01/lieber/ajaffe/lab and similar directories such as /dcl01/lieber/ajaffe/lab/brainseq_phase2, while other projects live inside directories named after individuals such as /dcl01/lieber/ajaffe/Nick. Thus, this makes it challenging to locate all the projects. Even after re-organizing files, we’ll have multiple “group home” directories given that we have multiple disks and no disk is large enough to store all the data. JHPCE admins send quarterly invoices that keeps track of expenses in two ways: for storage, it computes the size of the main paths such as /dcl01/lieber/ajaffe for compute hours, they keep track of the memory and compute hours used by each each individual for each compute node queue (namely, shared and bluejay) In 2021, we started to re-organize files as JHPCE’s admins now compute storage 1 level deeper than they used to, such as /dcl01/lieber/ajaffe/dir01 and /dcl01/lieber/ajaffe/dir02. The idea is that this extra level of information enables LIBD Finance to have more detailed information on which grant or project code to charge for the different storage costs we incur at JHPCE. We also want to avoid personal directories, thus the “group home” directories will become the root for each disk such as /dcl01/lieber/ajaffe/. Overall, this new organization can help us identify old data that could be deleted. Another issue we have with the current file organization at JHPCE is that we don’t know which data has to be backed up and which doesn’t. Files can be classified into: raw-data: FASTQ, images, sample phenotype tables, etc code: ideally version-controlled through GitHub processed-data: files generated by running some code on the raw-data or other processed data 14.1.2 Organization since 2021 Thus the new organization is like this. jhpce $ tree -a . ├── group_home_disk1 │   └── projectName_grantNumber/repositoryName │   ├── .git │   ├── .gitignore │   ├── README.md │   ├── code │   │   ├── run_all.sh │   │   ├── update_style.R │   │   ├── 01_some_analysis │   │   │   ├── 01_some_code.R │   │   │   └── 02_more_code.sh │   │   ├── 02_another_analysis │   │   │   ├── 01_initial_code.R │   │   │   └── 02_plot_hello.R │   │   └── 03_image_processing │   │   └── 01_img_process.sh │   ├── plots │   │   └── 02_another_analysis │   │   └── hello.pdf │   ├── processed-data │   │   ├── 01_some_analysis │   │   │   └── some_file.Rdata │   │   ├── 02_another_analysis │   │   │   └── some_data.Rdata │   │   └── 03_image_processing │   │   ├── sample1_processed.tiff │   │   └── sample2_processed.tiff │   ├── repositoryName.Rproj │   └── raw-data │   ├── FASTQ │   │   ├── sample1.fastq.gz │   │   └── sample2.fastq.gz │   ├── README.md │   ├── images │   │   ├── sample1_raw.tiff │   │   └── sample2_raw.tiff │   └── sample_phenotype.csv └── group_home_disk2 ├── backup_projectName_grantNumber/repositoryName │   ├── code │   ├── plots │   ├── processed-data │   └── raw-data ├── projectHello_grantRANDOM14515 └── projectTest_grantRANDOM0123 24 directories, 19 files In this example, /group_home_disk1/projectName_grantNumber has been backed up across JHPCE disks to /group_home_disk2/backup_projectName_grantNumber. Not shown in this view above, the backup will not be group-writable unlike the original location. For some projects we might just backup the raw-data, for others we’ll back up the code, plots and processed-data. /group_home_disk2 also contains it’s own unique projects that are not backed up at /group_home_disk1 (projectHello_grantRANDOM14515 and projectTest_grantRANDOM0123). /group_home_disk1/projectName_grantNumber has several components. .git: it is version controlled at that level using Git. .gitignore: specifies what files to ignore. Typically, raw-data and processed-data. It could also ignore plots though smaller plots could be version controlled using git add -f (-f forces Git to version that file even if it’s ignored in a .gitignore file). README.md: describes the project and some main features of the project. It should include the JHPCE location for the project as noted in the project documentation further below. code: contains directories that are ordered by using a two digit leading ID (or three if the project is huge). 01_some_analysis and 02_another_analysis: contain scripts also using a two digit leading ID to help organize the files in the order they should be used for re-generating the processed data and plots. plots: contains a directory matching the directory names used in code such that it is clear what code generate what plot. Here for plots/02_another_analysis/hello.pdf we can identify that the code for this plot lives at code/02_another_analysis/02_plot_hello.R. processed-data: also contains a directory matching the directory names used in code. raw-data: contains the raw data for the project. If the raw data is backed up elsewhere, then we can use symbolic links to point to the location of the data. For example, /group_home_disk1/projectName_grantNumber/repositoryName/raw-data/FASTQ could be a soft link to /dcl02/lieber/ajaffe/Nina/Joel_R01/Year1/fastq. This will be helpful to differentiate what is the raw data our group is responsible for backing up against the raw data the LIBD RNA-seq core facility or other entities are responsible for backing up. It also contains the sample phenotype information such as /group_home_disk1/projectName_grantNumber/repositoryName/raw-data/sample_phenotype.csv that is required for any analyses of the raw data. repositoryName.Rproj` an RStudio project file, which makes it easier to write R code. The project organization detailed shown above enables us to write code inside a project in such a way that if the disk where we store the project changes, none of the code has to change. That’s because we can use the here package as illustrated in the 2020-04-17 LIBD rstats club session (notes). 14.1.3 Project template You might be interested in checking out the template_project, which shows these organization guidelines in action. Some current examples are: LieberInstitute/ranger_metrics LieberInstitute/Visium_IF_AD LieberInstitute/DLPFC_snRNAseq LieberInstitute/spatialDLPFC 14.2 Project documentation As a minimum, each project should include a README.md file in the root folder for the project, such as /group_home_disk1/projectName_grantNumber/repositoryName/README.md. This README.md should include the following sections: title abstract / summary how to cite the project overview of the files and how they are organized internal notes JHPCE internal location Slack channel Any internal reminders, like setting the umask Additionally, nested directories could have their own README.md files. For example, /group_home_disk1/projectName_grantNumber/repositoryName/raw-data/README.md is one such README.md file which can describe where the raw-data has been backed up, such as saying “The raw data has been backed up at /group_home_disk2/backup_projectName_grantNumber/repositoryName/raw-data as of 2021-04-16.”. Other README.md files could show can show results such as this example from brainseq_phase2. If the project is quite big, it might make sense to make a documentation website such as the one we made for SPEAQeasy. The advantage of such websites is that they enable visitors to search and locate information more rapidly. Though they take longer to write. 14.3 Setting JHPCE file permissions The following video on how to move files and setup permissions might be useful. It covers the same material shown here. At JHPCE we have multiple user groups. Everyone within a user group has the same permissions, such that everyone is equal. That is, there is no user group admin role. As there are many JHPCE users, the typical approach is to make a user group and restrict read and/or write access to that user group. We use to do this with lieber_jaffe, but then the user group grew quite large over time and not everyone necessarily should have had read/write access to everything. This leads to having multiple user groups. One option is to create a user group for every specific project, but this requires constantly asking JHPCE’s admins (through BitSupport) for changes, since they are the only ones who can add/remove people to user groups, or even create them. This is where Access Control Lists (ACLs) come into play. See “An introduction to Linux Access Control Lists (ACLs)” for more details. That’s because if you have user groups that are small, such as those representing specific members of a given team/lab, then you say that team 1 should be given write and read access to project 1 teams 1 and 2 should be given write and read access to project 2 teams 1 and 2 should be given write and read access to project 3 and team 3 only given read access Some examples with actual teams are: Team (user group) lieber_lcolladotor is working on a private project. Team (user group) lieber_lcolladotor is working on a private project along with team (user group) lieber_marmaypag. Teams (user groups) lieber_lcolladotor and lieber_marmaypag created some files that we want to share with everyone at LIBD (lieber user group) but don’t want others to accidentally delete or modify them. For more details about ACLs at JHPCE check the Granting File Permissions using ACLs page. 14.3.1 Useful commands To check who belongs to a specific group, use getent group groupName. For example: $ getent group lieber_lcolladotor lieber_lcolladotor:*:4217:jstolz,aseyedia,neagles,lcollado,gpertea1,lhuuki,bpardo Note that 4217 is the actual user group ID. Sometimes we need to know that ID to run some ACL commands. To find all the user groups for a specific person, use the groups command. For example: $ groups lcollado lcollado : lieber_jaffe swdev leekgroup recount3 lieber docker lieber_lcolladotor epi stanley rnaseq lieber_marmaypag lieber_snps lieber_martinowich users libdandme lieber_cmc lieber_gursini lieber_moods 14.3.2 dcs04 scripts At /dcs04, we use the nfs4_setfacl and nfs4_getfacl commands to either set or get (list) the current ACL settings. This is different from the commands we use at /dcl01 or other disks, and depends on how JHPCE’s admins configured specific disks. You might find this email exchange I had with JHPCE’s admins in 2021 useful to understand more details about these commands. Ultimately, my exchanges with JHPCE’s admins led to two scripts we use frequently when setting file permissions. One of them is for the collaboration between lieber_lcolladotor, lieber_marmaypag and hickslab. The second one is for a collaboration between lieber_lcolladotor and lieber_moods, that we want lieber to be able to see. The files are: /dcs04/lieber/lcolladotor/_jhpce_org_LIBD001/update_permissions_spatialteam.sh Usage: sh /dcs04/lieber/lcolladotor/_jhpce_org_LIBD001/update_permissions_spatialteam.sh /dcs04/lieber/yourTeam/someProject_LIBDcode/yourRepository /dcs04/lieber/lcolladotor/_jhpce_org_LIBD001/update_permissions_moods.sh Usage: sh /dcs04/lieber/lcolladotor/_jhpce_org_LIBD001/update_permissions_moods.sh /dcs04/lieber/yourTeam/someProject_LIBDcode/yourRepository A very common problem arises from copying files to JHPCE (for example, through Cyberduck), as copying files doesn’t respect the ACL settings we specify. This also happens when you move file around at JHPCE using mv that already existed. So after uploading a file or moving it with mv, you will likely need to re-run these permission scripts. 14.3.2.1 spatialteam example /dcs04/lieber/lcolladotor/_jhpce_org_LIBD001/update_permissions_spatialteam.sh #!/bin/bash echo &quot;**** Updating permissions for $1 ****&quot; date echo &quot;&quot; if [[ $HOSTNAME == compute-* ]] || [[ $HOSTNAME == transfer-* ]]; then echo &quot;**** Note that warning/error messages are expected for files and directories that you are not the owner of.&quot; echo &quot;The expected warning/error messages are: &quot; echo &quot; &#39;Failed setxattr operation: Operation not permitted&#39;&quot; echo &quot; or &#39;chgrp: changing group of ‘some_JHPCE_file_path’: Operation not permitted&#39;&quot; echo &quot; or &#39;chmod: changing permissions of ‘some_JHPCE_file_path’: Operation not permitted&#39;.&quot; echo &quot;If for many files you are not the owner (creator of), you will get lots of these warning/error messages, this is expected!&quot; echo &quot;Error or warnings with another syntax are likely real. ****&quot; echo &quot;&quot; echo &quot;You will need to re-run this script anytime you upload files to JHPCE through Cyberduck / WinSCP as they break the ACLs.&quot; echo &quot;Every new team member on a given project will likely also need to run this script once.&quot; echo &quot;&quot; echo &quot;For more details about setting permissions at JHPCE using ACLs, please check https://lcolladotor.github.io/bioc_team_ds/organizing-your-work.html#setting-jhpce-file-permissions.&quot; echo &quot;&quot; echo &quot;This message will be displayed for 90 seconds before the script proceeds.&quot; echo &quot;That way you will have time enough to read it and/or copy it.&quot; sleep 90 echo &quot;&quot; echo &quot;**** Setting read (R), write (W), and execute (X) permissions for hickslab ****&quot; sleep 5 date find ${1} -type d -exec nfs4_setfacl -a &quot;A:g:hickslab@cm.cluster:RWX&quot; {} \\; find ${1} -type d -exec nfs4_setfacl -a &quot;A:gfdi:hickslab@cm.cluster:RWX&quot; {} \\; find ${1} -type f -exec nfs4_setfacl -a &quot;A:g:hickslab@cm.cluster:RW&quot; {} \\; echo &quot;&quot; echo &quot;**** Setting read (R), write (W), and execute (X) permissions for lieber_lcolladotor ****&quot; sleep 5 date find ${1} -type d -exec nfs4_setfacl -a &quot;A:g:lieber_lcolladotor@cm.cluster:RWX&quot; {} \\; find ${1} -type d -exec nfs4_setfacl -a &quot;A:gfdi:lieber_lcolladotor@cm.cluster:RWX&quot; {} \\; find ${1} -type f -exec nfs4_setfacl -a &quot;A:g:lieber_lcolladotor@cm.cluster:RW&quot; {} \\; echo &quot;&quot; echo &quot;**** Setting read (R), write (W), and execute (X) permissions for lieber_marmaypag ****&quot; sleep 5 date find ${1} -type d -exec nfs4_setfacl -a &quot;A:g:lieber_marmaypag@cm.cluster:RWX&quot; {} \\; find ${1} -type d -exec nfs4_setfacl -a &quot;A:gfdi:lieber_marmaypag@cm.cluster:RWX&quot; {} \\; find ${1} -type f -exec nfs4_setfacl -a &quot;A:g:lieber_marmaypag@cm.cluster:RW&quot; {} \\; ## To move away from lieber_jaffe echo &quot;&quot; if getent group lieber_lcolladotor | grep -q &quot;\\b${USER}\\b&quot;; then echo &quot;**** Running chgrp lieber_lcolladotor ****&quot; sleep 5 date chgrp lieber_lcolladotor -R ${1} elif getent group lieber_marmaypag | grep -q &quot;\\b${USER}\\b&quot;; then echo &quot;**** Running chgrp lieber_marmaypag ****&quot; sleep 5 date chgrp lieber_marmaypag -R ${1} elif getent group hickslab | grep -q &quot;\\b${USER}\\b&quot;; then echo &quot;**** Running chgrp hickslab ****&quot; sleep 5 date chgrp hickslab -R ${1} else echo &quot;**** Skipping chgrp step ****&quot; fi ## For setting the group sticky bit echo &quot;&quot; echo &quot;**** Setting the group sticky bit ****&quot; sleep 5 date find ${1} -type d | xargs chmod g+s ## Check settings echo &quot;&quot; echo &quot;**** Checking the nfs4 (ACLs) settings ****&quot; sleep 5 date nfs4_getfacl ${1} else echo &quot;**** This script can only work on a qrsh / qsub session. It does not work on a login node since it does not have access to the nfs4_setfacl and nfs4_getfacl commands.****&quot; fi 14.3.2.2 lieber_moods example /dcs04/lieber/lcolladotor/_jhpce_org_LIBD001/update_permissions_moods.sh #!/bin/bash echo &quot;**** Updating permissions for $1 ****&quot; date echo &quot;&quot; if [[ $HOSTNAME == compute-* ]] || [[ $HOSTNAME == transfer-* ]]; then echo &quot;**** Note that warning/error messages are expected for files and directories that you are not the owner of.&quot; echo &quot;The expected warning/error messages are: &quot; echo &quot; &#39;Failed setxattr operation: Operation not permitted&#39;&quot; echo &quot; or &#39;chgrp: changing group of ‘some_JHPCE_file_path’: Operation not permitted&#39;&quot; echo &quot; or &#39;chmod: changing permissions of ‘some_JHPCE_file_path’: Operation not permitted&#39;.&quot; echo &quot;If for many files you are not the owner (creator of), you will get lots of these warning/error messages, this is expected!&quot; echo &quot;Error or warnings with another syntax are likely real. ****&quot; echo &quot;&quot; echo &quot;You will need to re-run this script anytime you upload files to JHPCE through Cyberduck / WinSCP as they break the ACLs.&quot; echo &quot;Every new team member on a given project will likely also need to run this script once.&quot; echo &quot;&quot; echo &quot;For more details about setting permissions at JHPCE using ACLs, please check https://lcolladotor.github.io/bioc_team_ds/organizing-your-work.html#setting-jhpce-file-permissions.&quot; echo &quot;&quot; echo &quot;This message will be displayed for 90 seconds before the script proceeds.&quot; echo &quot;That way you will have time enough to read it and/or copy it.&quot; sleep 90 echo &quot;&quot; echo &quot;**** Setting read (R), write (W), and execute (X) permissions for lieber_moods ****&quot; sleep 5 date find ${1} -type d -exec nfs4_setfacl -a &quot;A:g:lieber_moods@cm.cluster:RWX&quot; {} \\; find ${1} -type d -exec nfs4_setfacl -a &quot;A:gfdi:lieber_moods@cm.cluster:RWX&quot; {} \\; find ${1} -type f -exec nfs4_setfacl -a &quot;A:g:lieber_moods@cm.cluster:RW&quot; {} \\; echo &quot;&quot; echo &quot;**** Setting read (R), write (W), and execute (X) permissions for lieber_lcolladotor ****&quot; sleep 5 date find ${1} -type d -exec nfs4_setfacl -a &quot;A:g:lieber_lcolladotor@cm.cluster:RWX&quot; {} \\; find ${1} -type d -exec nfs4_setfacl -a &quot;A:gfdi:lieber_lcolladotor@cm.cluster:RWX&quot; {} \\; find ${1} -type f -exec nfs4_setfacl -a &quot;A:g:lieber_lcolladotor@cm.cluster:RW&quot; {} \\; echo &quot;&quot; echo &quot;**** Setting read (R) and execute (X) permissions for lieber ****&quot; sleep 5 date find ${1} -type d -exec nfs4_setfacl -a &quot;A:g:lieber@cm.cluster:RX&quot; {} \\; find ${1} -type d -exec nfs4_setfacl -a &quot;A:gfdi:lieber@cm.cluster:RX&quot; {} \\; find ${1} -type f -exec nfs4_setfacl -a &quot;A:g:lieber@cm.cluster:R&quot; {} \\; echo &quot;&quot; echo &quot;**** Removing permissions for lieber_marmaypag ****&quot; sleep 5 date find ${1} -type d -exec nfs4_setfacl -x &quot;A:g:lieber_marmaypag@cm.cluster:rwaDxtcy&quot; {} \\; find ${1} -type d -exec nfs4_setfacl -x &quot;A:gfdi:lieber_marmaypag@cm.cluster:rwaDxtcy&quot; {} \\; find ${1} -type f -exec nfs4_setfacl -x &quot;A:g:lieber_marmaypag@cm.cluster:rwatcy&quot; {} \\; find ${1} -type d -exec nfs4_setfacl -x &quot;A:g:4218:rwaDxtcy&quot; {} \\; find ${1} -type d -exec nfs4_setfacl -x &quot;A:gfdi:4218:rwaDxtcy&quot; {} \\; find ${1} -type f -exec nfs4_setfacl -x &quot;A:g:4218:rwatcy&quot; {} \\; ## To move away from lieber_jaffe echo &quot;&quot; if getent group lieber_moods | grep -q &quot;\\b${USER}\\b&quot;; then echo &quot;**** Running chgrp lieber_moods ****&quot; sleep 5 date chgrp lieber_moods -R ${1} elif getent group lieber_lcolladotor | grep -q &quot;\\b${USER}\\b&quot;; then echo &quot;**** Running chgrp lieber_lcolladotor ****&quot; sleep 5 date chgrp lieber_lcolladotor -R ${1} else echo &quot;**** Skipping chgrp step ****&quot; fi ## For setting the group sticky bit echo &quot;&quot; echo &quot;**** Setting the group sticky bit ****&quot; sleep 5 date find ${1} -type d | xargs chmod g+s ## Check settings echo &quot;&quot; echo &quot;**** Checking the nfs4 (ACLs) settings ****&quot; sleep 5 date nfs4_getfacl ${1} else echo &quot;**** This script can only work on a qrsh / qsub session. It does not work on a login node since it does not have access to the nfs4_setfacl and nfs4_getfacl commands.****&quot; fi 14.4 Moving files across JHPCE disks When you are moving files from other disks into /dcs04, you will likely need up to 4 files: one file listing the directories you want to move Optional, but useful if you are moving one that one directory into a particular destination directory and want to use a single array job for moving the directories. one script for moving files to /dcs04 with rsync We don’t use mv since it’s error prone and can have terrible consequences when it fails mid run. one script for updating the permissions Even if the script simply runs one of the permissions scripts covered in the earlier section, you might want to have a script you can qsub as scripts that update permissions for many files can take hours to run. one script for deleting the original files You will likely want to wait a few days / weeks before running this, to make sure that you have successfully moved everything you needed. If you don’t have write permissions to all the original files, you will need to request JHPCE’s admins to run this for you. 14.4.1 qSVA example In this example, we moved 3 different /dcl01 directories into /dcs04, hence the use of an array job. These 3 directories were all related to the qSVA R21 project that had the internal LIBD code 3080, hence why all of them were relocated to /dcs04/lieber/lcolladotor/qSVA_LIBD3080. To store the scripts and log files associated with the relocation, I used the _jhpce_org directory which I typically use for storing these types of files. We also wanted to list the owners of all original files (thanks Bill Ulrich for this code!) since sometimes having the owner is useful to know who to ask for help with a particular file. /dcs04/lieber/lcolladotor/qSVA_LIBD3080/_jhpce_org files: qSVA_dcl01_dirs.txt It contains the full paths to the 3 original directories that were relocated. /dcl01/ajaffe/data/lab/degradation /dcl01/ajaffe/data/lab/qsva_brain /dcl01/lieber/ajaffe/lab/degradation_experiments move_qSVA_dcl01.sh It’s an array job for 3 tasks which represent the directories (#$ -t 1:3). Note the increase of the maximum file size (h_fsize=400G), in case we are moving some very large files. To reduce the burden on the network, we only copied 2 directories at a time (#$ -tc 2; number of concurrent tasks). Before transferring all the data, we compute the total data size (in TB) of the transfer. We use the -sk --apparent-size options to the du command in order to compute the un-compressed disk size, since some disk systems automatically compress some files, which can lead to different file size calculations across disk systems. Once we have listed the owner of all files, we then move the files using rsync which will not preserve the original owner. The owner of all the transferred files (at /dcs04) will be the person who did the transfer. While doing this, we also change the unix group to the new one we want people to use. In this case, lieber_lcolladotor (the original files were most likely under lieber_jaffe). A nice thing about using rsync is that if it fails in the middle of a run, it can be resumed without problems later on. Once we have completed the transfer across disks, we move the original files using mv to a trash directory (here trash_qSVA). This frees up the original directory name, which we can then use to create a soft link from the original location to the new location. Creating this soft link (symlink) helps users of the original files locate these files even if we moved them across disks (assuming they still have permissions to read the new files). #!/bin/bash #$ -cwd #$ -l bluejay,mem_free=2G,h_vmem=2G,h_fsize=400G #$ -N move_qSVA_dcl01 #$ -o logs/move_qSVA_dcl01.$TASK_ID.txt #$ -e logs/move_qSVA_dcl01.$TASK_ID.txt #$ -m e #$ -t 1-3 #$ -tc 2 echo &quot;**** Job starts ****&quot; date echo &quot;**** JHPCE info ****&quot; echo &quot;User: ${USER}&quot; echo &quot;Job id: ${JOB_ID}&quot; echo &quot;Job name: ${JOB_NAME}&quot; echo &quot;Hostname: ${HOSTNAME}&quot; echo &quot;Task id: ${SGE_TASK_ID}&quot; ## List current modules for reproducibility module list ## Locate directory ORIGINALDIR=$(awk &quot;NR==${SGE_TASK_ID}&quot; qSVA_dcl01_dirs.txt) echo &quot;Processing sample ${ORIGINALDIR}&quot; date BASEDIR=$(basename ${ORIGINALDIR}) ORIGINALHOME=$(dirname ${ORIGINALDIR}) ## Determine amount of data to transfer du -sk --apparent-size ${ORIGINALDIR}/ | awk &#39;{$1=$1/(1024^3); print $1, &quot;TB&quot;;}&#39; ## List owners of all the files in the original path find ${ORIGINALDIR}/ -exec ls -l {} \\; | grep -v total | tr -s &#39; &#39; | cut -d &#39; &#39; -f3,9- ## Copy from dcl01 to dcs04 rsync -rltgvh --chown=:lieber_lcolladotor ${ORIGINALDIR}/ /dcs04/lieber/lcolladotor/qSVA_LIBD3080/${BASEDIR}/ ## Label as trash the files that were moved mkdir -p ${ORIGINALHOME}/trash_qSVA/ mv ${ORIGINALDIR} ${ORIGINALHOME}/trash_qSVA/ ## Create link ln -s /dcs04/lieber/lcolladotor/qSVA_LIBD3080/${BASEDIR} ${ORIGINALDIR} echo &quot;**** Job ends ****&quot; date ## This script was made using sgejobs version 0.99.1 ## available from http://research.libd.org/sgejobs/ update_permissions.sh By default, directories under /dcs04/lieber/lcolladotor have read, write and execute permissions to the lieber_marmaypag group. Here though, we first remove the permissions to lieber_marmaypag, then we give read and execute permissions to both the lieber and lieber_marmaypag unix user groups. We (redundantly) set the group of all files to be lieber_lcolladotor and then set the group sticky bit which preserves the group (lieber_lcolladotor in this case) to any new files created within these directories. Finally, we use nfs4_getfacl to check that the ACLs were set up correctly. Note how we use #$ -hold_jid with the same name of the script from the move step earlier (here move_qSVA_dcl01) so we can qsub this script immediately after the move one, but wait for them to finish running before this one starts. #!/bin/bash #$ -cwd #$ -l bluejay,mem_free=2G,h_vmem=2G,h_fsize=400G #$ -N update_permissions_qSVA #$ -o logs/update_permissions.txt #$ -e logs/update_permissions.txt #$ -m e #$ -hold_jid move_qSVA_dcl01 echo &quot;**** Job starts ****&quot; date echo &quot;**** JHPCE info ****&quot; echo &quot;User: ${USER}&quot; echo &quot;Job id: ${JOB_ID}&quot; echo &quot;Job name: ${JOB_NAME}&quot; echo &quot;Hostname: ${HOSTNAME}&quot; echo &quot;Task id: ${SGE_TASK_ID}&quot; ## List current modules for reproducibility module list MAINDIR=&quot;/dcs04/lieber/lcolladotor/qSVA_LIBD3080&quot; ## Remove default permissions find ${MAINDIR} -type d -exec nfs4_setfacl -x &quot;A:g:lieber_marmaypag@cm.cluster:rwaDxtcy&quot; {} \\; find ${MAINDIR} -type d -exec nfs4_setfacl -x &quot;A:gfdi:lieber_marmaypag@cm.cluster:rwaDxtcy&quot; {} \\; find ${MAINDIR} -type f -exec nfs4_setfacl -x &quot;A:g:lieber_marmaypag@cm.cluster:rwatcy&quot; {} \\; ## Set new permissions find ${MAINDIR} -type d -exec nfs4_setfacl -a &quot;A:g:lieber@cm.cluster:RX&quot; {} \\; find ${MAINDIR} -type d -exec nfs4_setfacl -a &quot;A:gfdi:lieber@cm.cluster:RX&quot; {} \\; find ${MAINDIR} -type f -exec nfs4_setfacl -a &quot;A:g:lieber@cm.cluster:R&quot; {} \\; find ${MAINDIR} -type d -exec nfs4_setfacl -a &quot;A:g:lieber_marmaypag@cm.cluster:RX&quot; {} \\; find ${MAINDIR} -type d -exec nfs4_setfacl -a &quot;A:gfdi:lieber_marmaypag@cm.cluster:RX&quot; {} \\; find ${MAINDIR} -type f -exec nfs4_setfacl -a &quot;A:g:lieber_marmaypag@cm.cluster:R&quot; {} \\; ## To move away from lieber_jaffe chgrp lieber_lcolladotor -R ${MAINDIR} ## For setting the group sticky bit find ${MAINDIR} -type d | xargs chmod g+s ## Check settings nfs4_getfacl ${MAINDIR} echo &quot;**** Job ends ****&quot; date ## This script was made using sgejobs version 0.99.1 ## available from http://research.libd.org/sgejobs/ delete_qSVA_dcl01.sh This script also uses #$ -hold_jid so in theory we could submit it (qsub) immediately after the move script, however, it’s best to wait a few days or weeks before running the script that deletes the original files under trash (here trash_qSVA), to make sure that we are not missing any files or encountered unexpected scenarios when moving files across disks. #!/bin/bash #$ -cwd #$ -l bluejay,mem_free=2G,h_vmem=2G,h_fsize=100G #$ -N delete_qSVA_dcl01 #$ -o logs/delete_qSVA_dcl01.txt #$ -e logs/delete_qSVA_dcl01.txt #$ -m e #$ -hold_jid move_qSVA_dcl01 echo &quot;**** Job starts ****&quot; date echo &quot;**** JHPCE info ****&quot; echo &quot;User: ${USER}&quot; echo &quot;Job id: ${JOB_ID}&quot; echo &quot;Job name: ${JOB_NAME}&quot; echo &quot;Hostname: ${HOSTNAME}&quot; echo &quot;Task id: ${SGE_TASK_ID}&quot; ## List current modules for reproducibility module list ## Delete dcl01 data rm -fr /dcl01/ajaffe/data/lab/trash_qSVA/ rm -fr /dcl01/lieber/ajaffe/lab/trash_qSVA/ echo &quot;**** Job ends ****&quot; date ## This script was made using sgejobs version 0.99.1 ## available from http://research.libd.org/sgejobs/ 14.4.2 HumanPilot example This is a simpler example, since we only moved one directory. So there’s no need for an array job or a file listing the directories we want to move. This project was done without any grant support, hence why we associated the LIBD 001 code to it. It was done in collaboration with 10x Genomics, hence why we decided to move it to /dcs04/lieber/lcolladotor/with10x_LIBD001. As in the previous example, I created a _jhpce_org directory to store the scripts related to relocating files and updating permissions. We also don’t have a script for deleting the files, since we knew that we didn’t have write permissions on all the original files and thus would need JHPCE’s admins help deleting them. This scenario is common when one or more people who were involved in the initial project leave LIBD prior to the file relocation, as you can’t ask them to run the delete script to delete the files they control. However, since we did have read access to all files, we were able to relocate them without needing JHPCE’s admins support. /dcs04/lieber/lcolladotor/with10x_LIBD001/_jhpce_org files: move_HumanPilot_dcl02.sh This script is similar to the qSVA example, but there is no array job. It was adapted from it, and thus we still specify the ORIGINALDIR environment variable, but we do it manually this time instead of using awk to do so. Most of the rest is the same, but here the trash directory is just called trash, as it became easier to do so and explain to JHPCE admins which directories we wanted deleted later on. #!/bin/bash #$ -cwd #$ -l bluejay,mem_free=2G,h_vmem=2G,h_fsize=400G #$ -N move_HumanPilot_dcl02 #$ -o logs/move_HumanPilot_dcl02.txt #$ -e logs/move_HumanPilot_dcl02.txt #$ -m e echo &quot;**** Job starts ****&quot; date echo &quot;**** JHPCE info ****&quot; echo &quot;User: ${USER}&quot; echo &quot;Job id: ${JOB_ID}&quot; echo &quot;Job name: ${JOB_NAME}&quot; echo &quot;Hostname: ${HOSTNAME}&quot; echo &quot;Task id: ${SGE_TASK_ID}&quot; ## List current modules for reproducibility module list ## Locate directory ORIGINALDIR=&quot;/dcl02/lieber/ajaffe/SpatialTranscriptomics/HumanPilot&quot; echo &quot;Processing directory ${ORIGINALDIR}&quot; date BASEDIR=$(basename ${ORIGINALDIR}) ORIGINALHOME=$(dirname ${ORIGINALDIR}) NEWDIR=&quot;/dcs04/lieber/lcolladotor/with10x_LIBD001/${BASEDIR}&quot; ## Determine amount of data to transfer du -sk --apparent-size ${ORIGINALDIR}/ | awk &#39;{$1=$1/(1024^3); print $1, &quot;TB&quot;;}&#39; ## List owners of all the files in the original path find ${ORIGINALDIR}/ -exec ls -l {} \\; | grep -v total | tr -s &#39; &#39; | cut -d &#39; &#39; -f3,9- ## Copy from dcl02 to dcs04 rsync -rltgvh --chown=:lieber_lcolladotor ${ORIGINALDIR}/ ${NEWDIR}/ ## Label as trash the files that were moved mkdir -p ${ORIGINALHOME}/trash/ mv ${ORIGINALDIR} ${ORIGINALHOME}/trash/ ## Create link ln -s ${NEWDIR} ${ORIGINALDIR} echo &quot;**** Job ends ****&quot; date ## This script was made using sgejobs version 0.99.1 ## available from http://research.libd.org/sgejobs/ update_permissions.sh This is a much simpler bash script which we didn’t qsub and basically just reminds us of the specific command we used to update the permissions. That way, if anyone asks us what we ran in the future, we know exactly how we updated the permissions. #!/bin/bash sh /dcs04/lieber/lcolladotor/_jhpce_org_LIBD001/update_permissions_spatialteam.sh /dcs04/lieber/lcolladotor/with10x_LIBD001 "],["writing-papers.html", "15 Writing papers 15.1 Things to keep in mind 15.2 Writing process 15.3 OneDrive: publication files 15.4 Revisions 15.5 Details", " 15 Writing papers On 2020-04-06 I presented at how to write papers using Google Docs. The video and notes mostly highlight these tools including Sciwheel and CrossReference. Most recently I presented at the LIBD rstats club more ideas behind writing papers. Here are the notes. 15.1 Things to keep in mind While you’ll want to check those videos and notes, a lot of it comes down to being organized and using the right tool for the job. In more detail, you’ll want to keep track of software versions as you develop your project so you have the information readily available when you write the methods. You’ll want to use big font sizes and consistent colors across your figures so you don’t have to re-make them later. Once you have a journal in mind, you’ll want to check the guidelines from that journal and potentially use their LaTeX template in Overleaf, although for a general journal, Google Docs works quite well and is easier to use by everyone. With both Overleaf or Google Docs (through the Cross Reference addin), you’ll definitely want to use automatic figure, table, equation, and citation numbers. Doing so will enable you to easily re-arrange your figures/tables/equations/citations and avoid having to manually update all numbers which would be very painful. Most journals will also require that you cite figures and tables in order of appearance and that all supplementary materials are referred to in the main text (introduction, results, discussion sections) or even be linked to a main figure/table. Funding is quite important too, so make sure that you check with all co-authors that all their funding sources are listed. Once the authors are defined, you’ll want to have their email, affiliation name(s), affiliation address(es), and ORCiD so you can fill that information in the journal website 24. Similarly, you and the team will want to think about potential reviewers which involves getting their emails and affiliations. A paper has a lot of components and you’ll need to check that the information provided is consistent, include small things such as (A) vs (a) in the figures. So it takes a while to write a paper and it’s best to subdivide it into many small tasks so you don’t feel overwhelmed. That way you can check off items off your list. If “write the paper” is the item in your list, it’ll feel like it never ends. 15.2 Writing process When we start a paper, we like to write bullet points for the different sections or results we want to show, as well as write in text the figures we would like to make. This makes it easier to then write one short paragraph at a time and to grow the paper that way while keeping an overall idea of the flow of the paper in mind. Editing is also easier to do than writing from scratch. So you can expect to receive edits 25 in the process of writing a paper. Other labs ask the first (co-first) to write a full draft. We prefer to write the paper together, although the lead writers might write most of the first versions for each paragraph while others will mostly edit. Given this style we use, it’s useful to re-read the final draft to make sure that we are consistent throughout the paper. For example, data set vs dataset. Also, don’t be shy with the methods and supplementary material. Typically, journals allow us to include as many details as we want. That way, you’ll be able to refer back to sections of you paper in the future when people ask you how you did X or Y part of the paper. In a similar sense, don’t be shy about tagging others in your paper in case you need feedback on a section you just wrote or you need others to help you write. We are a team in the end and are in this together =) 15.3 OneDrive: publication files In OneDrive 26, use a directory like submission_01 for the first submission as there will be multiple rounds for any paper. Follow this general structure for the publication files: submission_01 bioRxiv author information Manuscript: for the PDF/docx version of the manuscript and other files required by the journal such as the table describing software and methods used, the cover letter, etc. Figures: include a directory for every single Figure such that we can keep all files related to that figure in that directory and use Adobe Illustrator to link the different panels together. Name the directory with the same name you use for CrossReference. For example, fig_overview. if overview is the name you use in CrossReference. That makes it easy to remember what are the names you are using in CrossReference. Tables: if the tables are small, consider combining them into a single Excel file where you include one sheet with the table legends. Keep the advice from Karl Broman and Kara Woo in mind (DOI 10.1080/00031305.2017.1375989) when making the table files. In many journals, a table counts the same as a figure in terms of display items. We thus tend to not use tables (only supplementary tables). SupplementaryFigures: similar to Figures, you want to have each directory name to include the CrossReference code used for the figure. See the Mendelay Data example mentioned further below. SupplementaryTables: similar to SupplementaryFigures. If you have related supplementary tables, you could use an Excel file with multiple sheets. Remember to describe all columns, such that others can understand them without absolutely having to send an email asking about the table: you want to minimize getting lots of emails about them! Though of course, getting the occassional email because something wasn’t clear is ok. submission_02 Manuscript: revised manuscript, response to reviewers, cover letter, etc. Figures: any revised figures. Sometimes we copy them all if most of them have some modifications or if the numbers changed. Tables: any revised tables, similar to Figures. SupplementaryFigures: similar to Figures. SupplementaryTables: similar to SupplementaryFigures Unlike version controlled files in GitHub, for all files related to the publication, we will keep multiple copies of them across submission versions. 15.3.1 Examples See Regional heterogeneity in gene expression, regulation and coherence in hippocampus and prefrontal cortex across development and in schizophrenia. Collado-Torres et al, Neuron, 2019 on Mendeley Data which contains our final Figures/, SupplementaryFigures/ and SupplementaryTables/ directories. We shared all full resolution images as some were large files. A second example is Figures_Maynard_Collado-Torres_et_al_Nature_Neuroscience_2021.zip that contains the Figures/ and SupplementaryFigures/ directories for that paper. This included large .tiff images with RNAscope results that we thought others might be interested in using at some point, since the versions of the images on the paper itself are not high-resolution enough to extract data from them. Both Mendeley Data and Figshare give you a DOI that you can refer to in the manuscript of the paper associated with the figures and tables that you are sharing. 15.4 Revisions When responding to reviewers, make a new Google Doc where the feedback from the reviewers is in bold or some other font, and add placeholders for responses. You can then tag the co-author(s) that can help the most with the response for each point. As examples, check: the BrainSEQ Phase II Google Doc with code at LieberInstitute/brainseq_phase2 as well through Zenodo. The final version is available at DOI 10.1016/j.neuron.2019.05.013. the spatialLIBD project Google Doc with code at LieberInstitute/HumanPilot as well as through Zenodo. The final version is available at DOI 10.1038/s41593-020-00787-0. For an Overleaf example, check the spatialLIBD software paper. 15.5 Details Here are more details: Title: check character limits. Author list: affiliations numbers have to appear in order. Affiliations: include zip code and country. Abstract / summary: check word limits, don’t include citations. Introduction: motivate the problem we are trying to solve and give an short summary of what we did. Remember to define any acronyms. Results: describe what we found. For how we did things, refer to the appropriate methods section. Discussion: any speculation goes here as well as potential drawbacks to the work we did. You’ll also want to highlight the main results and conclusions from our work. Acknowledgements: information about the donors as well as any requests from consortiums like GTEx. Funding: include full grant IDs and who they supported. Author contributions: use the CRediT contributor roles taxonomy Conflicts of interest: in case any authors worked for companies, list that info here. Figure/table legends: figure/table number and figure/table title should be in bold font. Then the description in plain text. I also like to use (A) instead of (A) whenever the description of a sub-panel begins. Some journals will ask that you also link to all supplementary figure/tables from the main figures. Check also the allowed text length for figure legends. Methods: use sub-sections for the different parts of the work and sort them in order of appearance from the Results section. Use version numbers and a different font style for software / functions to make it easier to identify those words as names of tools. Cite every single software you used! Don’t interpret results here, that should be in the Results section. Data and software availability: link to GitHub and cite using Zenodo which provides DOIs for GitHub repositories as shown in this guide. Note that we start most of our GitHub repositories as private, but we make them public by the time we post a pre-print. You’ll want to have a high quality README.md in your repository that shows how the work should be cited and guides visitors to the different components included in the repository. Several journals will require to you also complete more detailed forms such as this Reporting Summary example from one of our papers. Finally, feel free to sign up for a Data Science guidance session with anyone in the team that recently wrote a paper. Note that bioRxiv has an author information template table that you can use.↩︎ Likely using suggestion mode in Google Docs. Also note that both Google Docs and Overleaf allow you to name versions, which makes it easier to refer back to them and compare against them.↩︎ In the past we used Dropbox, but because OneDrive is free through JHU, we switched to it.↩︎ "],["authorship.html", "16 Authorship", " 16 Authorship At any point if you have questions about authorship in a project, it’s best to bring it up rather than to assume. I feel that it’s best to communicate frequently as authorship for a given project evolves over time given that projects are always in flux. In general though, if you helped with any role as specified by the CRediT contributor roles taxonomy, you will be invited to be a co-author of the resulting publication. While we prepare a draft for a manuscript before we submit it to bioRxiv/medRxiv, and if you think that you should be considered a co-author but are not listed, please let us know! Sometimes projects get very large and it can be hard to remember who contributed to it so we might make unintentional mistakes. Ultimately, we don’t make promises about authorship positions before a project is done. We aspire to be fair and evaluate contributions when the project has been completed based solely on the project described and not other projects. We thus tend to complete the author list on a given manuscript once most of the draft has been written. Note that we frequently use co-first authors to indicate that multiple people contributed equally to a project. It’s up to you to make sure that you highlight this on your CV, particularly when you are the 2nd co-first author, given that automatic citation tools by default on mention the last name of the first author. Finally, we are generous with authorship. Though we do expect you to read the paper and provide feedback in a timely fashion before we submit it regardless of your position in the author list. "],["config-files.html", "17 Config files 17.1 R setup 17.2 R config files 17.3 Git config files 17.4 JHPCE files", " 17 Config files Here are some of my configuration files for working R and JHPCE. 17.1 R setup RStudio Desktop Preview version: https://rstudio.com/products/rstudio/download/preview/ R: latest versions that match Bioconductor release and devel macOS: you can download the latest “branch” and “devel” from https://mac.r-project.org/ Windows: https://cran.r-project.org/, also needs Rtools42 https://cran.r-project.org/bin/windows/Rtools/ RSwitch macOS: https://rud.is/rswitch/ Windows: I install the R versions in two different folders and switch them using RStudio’s global configuration options https://cran.r-project.org/ Bioconductor-devel docker image: http://bioconductor.org/help/docker/ Do you want to use @Bioconductor 3.15? That means that you’ll need to install R 4.2 on your computer from CRAN https://t.co/11yTIRMqlCFor macOS users, you might want to use to install 📦 deps for compilingsudo Rsource(\"https://t.co/ATL1ipla0M\")install.libs(\"all\")#rstats https://t.co/EXUpWINy5T pic.twitter.com/X2HEbY1Znm — 🇲🇽 Leonardo Collado-Torres (@lcolladotor) April 28, 2022 So in macOS I use: ## From https://mac.r-project.org/bin/ # sudo R source(&quot;https://mac.R-project.org/bin/install.R&quot;) install.libs(&quot;all&quot;) and on winOS I install Rtools (latest version) from https://cran.r-project.org/bin/windows/Rtools/. Additional software: Both: Notion, Slack Windows: WinSCP, Git bash, PuTTY, Notepad++, NppToR macOS: Cyberduck, iTerm2, Alfred, TextMate2 You might also be interested in checking out our older onboarding setup materials. 17.1.1 R packages The following R code installs all the packages I have installed currently as my base. Many of them are packages I have made or contributed to as you can see at lcolladotor.github.io/pkgs. As I explore packages, I might try new ones that are not in this list. ## Install from scratch if (!requireNamespace(&quot;remotes&quot;, quietly = TRUE)) install.packages(&quot;remotes&quot;) remotes::install_cran(&quot;BiocManager&quot;) BiocManager::version() ## Rprofile packages if (.Platform$OS.type != &quot;windows&quot;) { remotes::install_github( &quot;jalvesaq/colorout&quot; ) } remotes::install_github(&quot;gaborcsardi/prompt&quot;) remotes::install_cran(c( &quot;devtools&quot;, &quot;usethis&quot; )) ## Laptop R profile packages (not needed at JHPCE) remotes::install_github(c( &quot;gadenbuie/rsthemes&quot; )) remotes::install_cran(&quot;suncalc&quot;) rsthemes::install_rsthemes(include_base16 = TRUE) remotes::install_github(&quot;gadenbuie/xaringanExtra&quot;) ## JHPCE R profile packages remotes::install_github(&quot;cloudyr/rmote&quot;) ## Main packages BiocManager::install(c( &quot;biocthis&quot;, &quot;brainflowprobes&quot;, &quot;derfinder&quot;, &quot;derfinderPlot&quot;, &quot;GenomicState&quot;, &quot;megadepth&quot;, &quot;qsvaR&quot;, &quot;recount&quot;, &quot;recountWorkflow&quot;, &quot;recount3&quot;, &quot;regutools&quot;, &quot;regionReport&quot;, &quot;spatialLIBD&quot;, &quot;TREG&quot; ), dependencies = TRUE, update = FALSE) ## LIBD packages remotes::install_github(c( &quot;LieberInstitute/DeconvoBuddies&quot;, &quot;LieberInstitute/jaffelab&quot;, # &quot;LieberInstitute/recount.bwtool&quot;, ## Not really used anymore &quot;LieberInstitute/sgejobs&quot;, &quot;LieberInstitute/shinycsv&quot; ), dependencies = TRUE) ## CRAN packages remotes::install_cran(c( &quot;ari&quot;, &quot;bookdown&quot;, &quot;blogdown&quot;, &quot;clue&quot;, &quot;corrplot&quot;, &quot;getopt&quot;, &quot;ggpubr&quot;, &quot;ggrepel&quot;, &quot;ggthemes&quot;, &quot;googlesheets4&quot;, &quot;MatrixEQTL&quot;, &quot;pagedown&quot;, &quot;patchwork&quot;, &quot;postcards&quot;, &quot;reprex&quot;, &quot;rsconnect&quot;, &quot;rtweet&quot;, &quot;tidyverse&quot;, &quot;xaringan&quot;, &quot;xaringanthemer&quot;, &quot;UpSetR&quot;, &quot;VennDiagram&quot; )) ## Bioc packages BiocManager::install(c( &quot;BiocCheck&quot;, &quot;ComplexHeatmap&quot;, &quot;ExploreModelMatrix&quot;, &quot;iSEE&quot;, &quot;scater&quot;, &quot;scran&quot;, &quot;sva&quot;, &quot;variancePartition&quot; ), update = FALSE) ## GitHub packages remotes::install_github(c( &quot;clauswilke/colorblindr&quot;, ## Install from GitHub due to https://github.com/immunogenomics/harmony/issues/145 &quot;immunogenomics/harmony&quot;, &quot;satijalab/azimuth&quot; )) ## Related to https://github.com/gusevlab/fusion_twas/issues/14 remotes::install_github( &quot;carbocation/plink2R/plink2R&quot;, ref = &quot;carbocation-permit-r361&quot; ) ## Packages I only install at JHPCE remotes::install_github(c( &quot;muschellij2/clusterRundown&quot; )) 17.1.1.1 Previously installed As I described in my blog post on updating R, I also like to saved my list of currently installed packages. ## Save currently installed packages installed_path &lt;- ifelse( .Platform$OS.type != &quot;windows&quot;, &quot;~/Dropbox/Computing/R&quot;, &quot;C:/Users/fellg/Dropbox/Computing/R&quot; ) ## At JHPCE I use: installed_path &lt;- &quot;~/R/update_R&quot; installed &lt;- dir(.libPaths()) save(installed, file = file.path(installed_path, paste0(Sys.Date(), &#39;-installed.Rdata&#39;))) ## Load previous &quot;installed&quot; packages previous &lt;- dir(path = installed_path, pattern = &#39;installed.Rdata&#39;) load(file.path(installed_path, previous[length(previous)]), verbose = TRUE) ## Locate current packages current &lt;- dir(.libPaths()) ## Use the following at JHPCE: current &lt;- dir(.libPaths()[1]) ## Missing ones installed[!installed %in% current] ## Install missing packages BiocManager::install(installed[!installed %in% current]) ## List new R packages current[!current %in% installed] You might also benefit from watching this video and checking the companion notes. If you want to install multiple R and Bioconductor versions, then you might find this second video and companion notes useful. 17.2 R config files 17.2.1 ~/.Rprofile Edit it with usethis::edit_r_profile(). Don’t add any analysis packages here as discussed in the “what they forgot to teach you about R” workshop. ## Change colors # Source https://github.com/jalvesaq/colorout if(Sys.getenv(&#39;TERM&#39;) %in% c(&quot;term&quot;, &quot;xterm-256color&quot;, &quot;cygwin&quot;, &quot;screen&quot;)) { if (!requireNamespace(&quot;colorout&quot;, quietly = TRUE) &amp; .Platform$OS.type != &#39;windows&#39;) { cat(&#39;To install colorout use: remotes::install_github(&quot;jalvesaq/colorout&quot;)\\n&#39;) } } # https://bookdown.org/yihui/blogdown/global-options.html options(blogdown.author = &#39;L. Collado-Torres&#39;) options(blogdown.ext = &#39;.Rmd&#39;) options(blogdown.insertimage.usebaseurl = TRUE) ## From RStudio::conf 2019 Building Tidy Tools if (interactive()) { suppressMessages(require(&quot;devtools&quot;)) suppressMessages(require(&quot;usethis&quot;)) suppressMessages(require(&quot;testthat&quot;)) options( warnPartialMatchArgs = TRUE, warnPartialMatchDollar = TRUE, warnPartialMatchAttr = TRUE ) } ## https://blog.rstudio.com/2013/06/10/rstudio-cran-mirror/ options(repos = c(CRAN = &quot;https://cloud.r-project.org/&quot;)) ## For usethis::use_git() options(usethis.protocol = &quot;ssh&quot;) ## For usethis options( usethis.full_name = &quot;Leonardo Collado-Torres&quot;, usethis.description = list( `Authors@R` = &#39;c( person(&quot;Leonardo&quot;, &quot;Collado-Torres&quot;, role = c(&quot;aut&quot;, &quot;cre&quot;), email = &quot;lcolladotor@gmail.com&quot;, comment = c(ORCID = &quot;0000-0003-2140-308X&quot;)) )&#39; ) ) ## For biocthis options(&quot;biocthis.pkgdown&quot; = TRUE) options(&quot;biocthis.testthat&quot; = TRUE) ## For the styler addin # Affects the output of: styler:::get_addins_style_transformer_name() # https://github.com/r-lib/styler/blob/acfb42acc2e558e7b57ef133f1470df78b5093fd/R/addins.R#L183 options(&quot;styler.addins_style_transformer&quot; = &quot;biocthis::bioc_style()&quot;) ## From https://www.garrickadenbuie.com/project/rsthemes/ if (interactive() &amp;&amp; requireNamespace(&quot;rsthemes&quot;, quietly = TRUE)) { # Set preferred themes if not handled elsewhere.. rsthemes::set_theme_light(&quot;base16 Monokai {rsthemes}&quot;) # light theme rsthemes::set_theme_dark(&quot;base16 Pop {rsthemes}&quot;) # dark theme rsthemes::set_theme_favorite(c( &quot;base16 Monokai {rsthemes}&quot;, &quot;base16 Pop {rsthemes}&quot;, &quot;base16 Brewer {rsthemes}&quot;, &quot;One Dark {rsthemes}&quot;, &quot;Solarized Light {rsthemes}&quot; )) # Whenever the R session restarts inside RStudio... setHook(&quot;rstudio.sessionInit&quot;, function(isNewSession) { # Automatically choose the correct theme based on time of day ## Used rsthemes::geolocate() once rsthemes::use_theme_auto(lat = 39.2891, lon = -76.5583) }, action = &quot;append&quot;) } ## From https://twitter.com/hadleywickham/status/1113542388033699840 if(interactive()) { if (!requireNamespace(&quot;prompt&quot;, quietly = TRUE)) { cat(&#39;To install prompt use: remotes::install_github(&quot;gaborcsardi/prompt&quot;)\\n&#39;) } else { prompt::set_prompt(prompt::prompt_git) } } 17.2.2 ~/.Renviron Edit it with usethis::edit_r_environ(). Here you can keep personal access tokens (PATs). GITHUB_PAT=something_provite TWITTER_PAT=a_private_file_path 17.2.3 ~/.R/Makevars I don’t have anything in this file since R 4.0 on my macOS laptop. 17.3 Git config files 17.3.1 ~/.gitconfig Edit it with usethis::edit_git_config(). Note that my editor is TextMate2 on macOS which can be accessed through the mate -w command. [user] name = Leonardo Collado Torres email = lcolladotor@gmail.com [core] editor = mate -w ignorecase = true [difftool &quot;sourcetree&quot;] cmd = opendiff \\&quot;$LOCAL\\&quot; \\&quot;$REMOTE\\&quot; path = [mergetool &quot;sourcetree&quot;] cmd = /Applications/SourceTree.app/Contents/Resources/opendiff-w.sh \\&quot;$LOCAL\\&quot; \\&quot;$REMOTE\\&quot; -ancestor \\&quot;$BASE\\&quot; -merge \\&quot;$MERGED\\&quot; trustExitCode = true [alias] ci = commit st = status br = branch co = checkout last = log -1 HEAD visual = gitk [push] default = simple [svn] rmdir = true [commit] 17.3.2 ~/.gitignore_global Edit it with usethis::edit_git_ignore(). These files are ignored by default by git on my computer. I no longer have this file since many people didn’t have it, so they would see files with git status that I wouldn’t. To simplify things, I have deleted this (for now). 17.4 JHPCE files To configure your computer with JHPCE, you might want to check this video and companion notes for macOS or this other video and companion notes for winOS. These videos also talk about GitHub and local git setup on your laptop. 17.4.1 ~/.sge_request This file configures the default SGE requests under qsub and qrsh. # Check http://www.biostat.jhsph.edu/bit/cluster-usage.html for more instructions # # Set defaults for mem_free and h_vmem -l mem_free=12G,h_vmem=12G # # Set the standard value for stack size limit # (needed for some programs to run properly when h_vmem is set) -l h_stack=256M # # Set a default maximum file size that an SGE job can create -l h_fsize=100G # Define my email -M YOUR_EMAIL@gmail.com # To get an email on a job use -m e # Keep in mind the limits with sending emails from # https://jhpce.jhu.edu/email-qsub 17.4.2 ~/.bashrc This is the main configuration file for JHPCE, but it’s really for any linux system. Some of the commands have to change when working on macOS. # .bashrc # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi # User specific aliases and functions # Auto-complete command from history # http://lindesk.com/2009/04/customize-terminal-configuration-setting-bash-cli-power-user/ export INPUTRC=~/.inputrc # http://www.biostat.jhsph.edu/~afisher/ComputingClub/webfiles/KasperHansenPres/IntermediateUnix.pdf # https://unix.stackexchange.com/questions/48713/how-can-i-remove-duplicates-in-my-bash-history-preserving-order export HISTCONTROL=ignoreboth:erasedups export HISTSIZE=20000 shopt -s histappend shopt -s cmdhist # http://superuser.com/questions/384769/alias-rm-rm-i-considered-harmful alias rmi=&#39;rm -i&#39; # Change command prompt # http://www.cyberciti.biz/tips/howto-linux-unix-bash-shell-setup-prompt.html # http://www.cyberciti.biz/faq/bash-shell-change-the-color-of-my-shell-prompt-under-linux-or-unix/ # https://bbs.archlinux.org/viewtopic.php?id=48910 # previous in enigma2: &quot;[\\u@\\h \\W]\\$ &quot; # previously in mac: &quot;\\h:\\W \\u\\$ &quot; export PS1=&quot;\\[\\e[0;33m\\]\\A \\W \\$ \\[\\e[m\\]&quot; # LIDB projects alias labold=&quot;cd /dcl01/lieber/ajaffe/lab&quot; alias lab=&quot;cd /dcl01/ajaffe/data/lab&quot; ## 10X genomics alias single=&quot;cd /dcl01/ajaffe/data/lab/singleCell&quot; alias spatialold=&quot;cd /dcl02/lieber/ajaffe/SpatialTranscriptomics/HumanPilot&quot; alias spatial=&quot;cd /dcl02/lieber/ajaffe/SpatialTranscriptomics/LIBD&quot; alias matt=&quot;cd /dcl01/lieber/ajaffe/Matt/MNT_thesis/snRNAseq/10x_pilot_FINAL&quot; ## Team home directories alias dcl01=&quot;cd /dcl01/lieber/lcolladotor&quot; alias dcl02=&quot;cd /dcl02/lieber/lcolladotor&quot; alias dcs04=&quot;cd /dcs04/lieber/lcolladotor&quot; ## Creating modules # https://lmod.readthedocs.io/en/latest/050_lua_modulefiles.html alias modsrc=&quot;cd /jhpce/shared/jhpce/libd&quot; alias modlua=&quot;cd /jhpce/shared/jhpce/modulefiles/libd&quot; # colors # http://norbauer.com/notebooks/code/notes/ls-colors-and-terminal-app # used BSD pattern ExGxFxDxBxEgEdxbxgxhxd on http://geoff.greer.fm/lscolors/ # that tool does not specify the colors, which I did by looking manually at # http://blog.twistedcode.org/2008/04/lscolors-explained.html # and the norbauer.com site previously mentioned alias ls=&quot;ls --color=auto&quot; #export LS_COLORS=&quot;di=1;34;40:ln=1;36;40:so=1;35;40:pi=1;93;40:ex=1;31;40:bd=1;34;46:cd=1;34;43:su =0;41:sg=0;46:tw=0;47:ow=0;43&quot; ## After switching to RStudio: # https://askubuntu.com/questions/466198/how-do-i-change-the-color-for-directories-with-ls-in-the- console export LS_COLORS=&quot;di=0;32:ln=0;36:so=0;35:pi=0;93:ex=0;31:bd=0;34;46:cd=0;34;43:su=0;41:sg=0;46:tw=0;47:ow=0;43:fi=0;33&quot; # Uncomment below for Mac and comment the two previous commands #export CLICOLOR=1 #export LSCOLORS=&quot;ExGxFxDxBxEgEdxbxgxhxd&quot; ## For setup: # http://erniemiller.org/2011/12/12/textmate-2-rmate-awesome/ ## For laptop config: # http://jonsimpson.co.uk/log/2011/rmate-ssh-remoteforward ## rmate port # https://github.com/textmate/rmate export RMATE_PORT=&quot;SOME_PORT_YOU_CHOOSE&quot; ## Load the git module by default when qrsh/qsub ## thanks to Jiong Yang if [[ $HOSTNAME == compute-* ]] || [[ $HOSTNAME == transfer-* ]]; then echo &quot;Adding LIBD modules&quot; module use /jhpce/shared/jhpce/modulefiles/libd echo &quot;Loading git&quot; module load git module load git-status-size/github module load git-lfs/2.8.0 module load rmate/1.5.10 module load conda_R/4.2.x fi ## To deal with running nextflow without requesting much more memory ## https://jhpce.jhu.edu/question/why-do-i-get-memory-errors-when-running-java/ export _JAVA_OPTIONS=&quot;-Xms5g -Xmx6g&quot; ## From https://twitter.com/fellgernon/status/1258455434073124865?s=20 ## and https://www.cyberciti.biz/tips/understanding-linux-unix-umask-value-usage.html umask u=rwx,g=rwx,o= ## equivalent to umask 007 For more information on rmate and rmote and how it relates to these configuration files, check this video and companion notes. 17.4.3 ~/.bash_profile This file is basically empty, since all the information is contained in the ~/.bashrc. That was the recommended setup a few years ago when I asked JHPCE’s admins. # .bash_profile # Get the aliases and functions if [ -f ~/.bashrc ]; then . ~/.bashrc fi 17.4.4 ~/.inputrc Useful for altering the behavior of the up and down arrow keys. See the companion lines on the ~/.bashrc file. #Page up/page down &quot;\\e[B&quot;: history-search-forward &quot;\\e[A&quot;: history-search-backward $include /etc/inputrc "],["how-to-contribute.html", "18 How to contribute 18.1 GitHub Issues 18.2 Team websites 18.3 GitHub Actions 18.4 LIBD R/Bioconductor packages", " 18 How to contribute You can play a very important role in improving the projects from the group. While we write software with the hope that others will use it, we are the first users and thus any questions we have are very likely to be questions external users will have. The earlier we fix these issues the better as more people will benefit from the improvements. Overall, there are many ways in you can help. Below is a list of some areas you might be interested in contributing to. 18.1 GitHub Issues Given that we use GitHub for most of our projects, one of the most direct ways to start contributing is by raising issues. There are many things we can do with issues as highlighted by this guide. However, their main use is to help us improve our own code and documentation. For example, maybe the help file for a function in one of our packages has a typo, is not clear, or assumes a lot of background knowledge. Letting the team know that that’s the case is the first step. Let’s say that we want to write an issue about the jaffelab::expression_cutoff() function. The following steps show you what I would do. Go to the GitHub repository for jaffelab which is https://github.com/LieberInstitute/jaffelab. Then I would find the latest commit from https://github.com/LieberInstitute/jaffelab/commits/master, which right now is https://github.com/LieberInstitute/jaffelab/commit/6a1c61bb3748aeb73890c1ab2aa59e5cc20bc08b. Then I would click on “browse files” which takes me to https://github.com/LieberInstitute/jaffelab/tree/6a1c61bb3748aeb73890c1ab2aa59e5cc20bc08b. 1. There, you can navigate to the file of interest, in this case, https://github.com/LieberInstitute/jaffelab/blob/6a1c61bb3748aeb73890c1ab2aa59e5cc20bc08b/R/expression_cutoff.R. Next you can highlight the relevant lines. In this case, we think that the definition of the expr argument can be improved. So that corresponds to https://github.com/LieberInstitute/jaffelab/blob/6a1c61bb3748aeb73890c1ab2aa59e5cc20bc08b/R/expression_cutoff.R#L13-L14. Next we can go to the issues page at https://github.com/LieberInstitute/jaffelab/issues and click on “New issue” and write the description of the problem we found while linking to the exact lines of code we think need to change. GitHub will then automatically show the code in the final issue and our issue will be protected in the sense that if the code at R/expression_cutoff.R changes and the lines we wanted to link to move around, our link will not be affected since we are linking to a specific past version of the code. Here’s the result https://github.com/LieberInstitute/jaffelab/issues/7. Once an issue has been raised, others or even yourself might want to address the request and make the necessary changes to resolve the issue. The above issue was resolved by this commit. A well documented issue makes everyone’s job easier and will help us improve our code and documentation. 18.2 Team websites You are definitely welcome to contribute to the several team websites such as this one. Here’s a non-comprehensive list of these repositories: https://github.com/lcolladotor/bioc_team_ds https://github.com/lcolladotor/DSgs_logs https://github.com/lcolladotor/team_surveys The above repositories are configured to update automatically using GitHub Actions and bookdown. 18.2.1 LIBD rstats club website One of the main contributions you might be interested in contributing is blog posts. This involves two repositories as described in this blog post. Since that blog post was written a few things have changed, although the overall idea remains. That is, we have two repositories: https://github.com/LieberInstitute/rstatsclubsource https://github.com/LieberInstitute/rstatsclub I basically control the second one and your contributions should be at https://github.com/LieberInstitute/rstatsclubsource, which is how we setup things to keep blog post authors anonymous. You’ll likely contribute an Rmd and an html file inside the content/post directory. You might also want to add information about yourself at content/authors. I recommend reading the blog post on how to contribute to this website and then meet with one of the recent blog post authors for a Data Science guidance session. 18.3 GitHub Actions GitHub Actions are quite powerful and we are increasingly using them in several of our projects. The basic idea is that they enable us to use free computers for up to 6 hours to run some code whenever we make a GitHub push. So they are ideal for running code in standarized environments that would otherwise take us time to run in our local computers. For example, automatic R package checks or rendering the HTML files for a website. 18.3.1 R packages biocthis is the R/Bioconductor package I developed for using GitHub Actions to test R packages in a Bioconductor-friendly way. In 2020-09-10 I presented biocthis to the Ryten lab and you can see the video and recording below. Ultimately, you’ll likely be interested in checking the documentation at https://lcolladotor.github.io/biocthis/ which includes a vignette describing the whole process for making this package. The main functions you’ll be interested in are biocthis::use_bioc_pkg_templates() as well as biocthis::use_bioc_github_action(). 18.3.2 Websites For rendering websites, I’ve edited the biocthis GitHub action workflow to render websites using bookdown or regular R markdown. Some additional repositories beyond the ones listed earlier that implement these workflows are: https://github.com/LieberInstitute/SPEAQeasy (bookdown) https://github.com/LieberInstitute/SPEAQeasy-example (bookdown) https://github.com/LieberInstitute/VisiumLIBD (bookdown) https://github.com/LieberInstitute/recount3-docs (bookdown and postcards) https://github.com/lcolladotor/twitter-stats (rmarkdown) 18.4 LIBD R/Bioconductor packages As a group we have many R/Bioconductor packages. I’ve created a list of the ones I’m involved in at lcolladotor.github.io/pkgs/ which might have errors or open issues that need to be addressed. If you want to help with any of them or with other LIBD R/Bioconductor R packages, the most direct way to get involved is to open a new issue to start communicating with the maintainer(s) of the package. For external R/Bioconductor packages, at some point in the LIBD rstats club we’ll have a session on how to make a pull request (TODO). "],["career-growth.html", "19 Career growth 19.1 Resources 19.2 Career planning session", " 19 Career growth While I would love that the people I’ve trained continued collaborating with me such that I can depend on them, everyone has different personal goals in mind and directions they want to take. Part of my job is to help you grow in the direction that you are interested in. To do so effectively, I need to hear from you since it’s impossible for me to know your thoughts. 19.1 Resources How to be a modern scientist by Jeff Leek has a chapter on career planning, which is written with students and postdocs in mind as is an adaptation of Ben Langmead’s postdoc questionnaire. However, I still think that most of this chapter applies regardless of your current position. This book is cheap (and you can get it for free) and is part of the recommended material. You might find this video useful on how to make your own website using postcards. You might also be interested in reading these books or at least checking the video/presentation about them. These books are not free, but I might have a copy that I could lend to you for a relatively short period of time. Getting to yes Suddenly in charge 19.2 Career planning session If I’m asking you to have a career planning session with me, please do the following: read the career planning chapter by Jeff Leek create a Google document where you answer at least the following questions, then share it to me before the meeting If we have met in the past, then write your new answers at the top of the document, but leave the older ones there, to remind us both of the progression of your choices over time. What is the next step you want to take in your career? 27 What are the main requirements? 28 Example job/grad/med school ad links can be useful to identify common requirements or what you like about them. What is the time window you have in mind? Who are you? Who do you want to be? What do you want people to notice about you? What is the main resource for people to find information about you? 29 What do you want to learn? What are the main projects you want to complete or work on? What conferences / seminars / hackathons are you interested in attending? Knowing when they are and what they request for presenting and for scholarships is useful for planning. If you feel like other questions from Ben’s list are relevant to you, feel free to answer them too. Some examples are: acquiring more responsibilities at LIBD, a change in title at LIBD, applying for grad/med school, a postdoc, a faculty job, an industry job.↩︎ For some jobs and applications you need recommendation letters, for others you need papers, for others you need to pass some type of test, for others you need to give a talk, or there might be specific courses you have to take.↩︎ You might have a LinkedIn profile, a website, a CV, a blog, a (professional) Twitter account, a GitHub profile, etc.↩︎ "],["project-code-handoff-checks.html", "20 Project code handoff checks", " 20 Project code handoff checks At some point, it might be time for you to move on to a different opportunity. We will miss you! But before you go, there are some things we should check, to make sure we understand the code and files in the project(s) you were working on. Is the code version controlled? Do we have access to the GitHub repository? Is the repository available on the LieberInstitute organization account? Is the home directory on JHPCE listed on the main README.md? Do we have access to the files on JHPCE? Do we have write access to these files? Check with nfs4_getfacl and/or ls -lah. Is there a clean git status output? Are the files organized as specified in “Organizing your work”? If not, is there one or more README.md files explaining how the files are organized and which code was run first, then second, etc? Is there sessioninfo::session_info() output on the log files or commented on the R scripts? This is useful for reproducibility and for writing the methods sections of papers. Check if any of the packages were installed from GitHub. If so, ask why GitHub versions were needed. For example, harmony/issues/145. Note this on the README.md or as a comment on the top of the script. Are the scripts linear? That is, can they be re-run from line 1 till the end linearly? Ideally: are there companion shell scripts for the R scripts? For example, Visium_IF_AD/run_all_post_spaceranger.sh. Do we know how much RAM or how many cores are required for each script? Ideally: This can be well documented with the companion shell scripts. Less ideal but still good: code comments noting the qrsh / qsub commands used. Do we know about any JHPCE modules that need to be loaded for running these scripts? Ideally: this can be documented on the companion shell scripts. Do the scripts have comments? Do we know which script was used for making each plot or output file? Sometimes plot names have been duplicated across scripts, leading to ambiguity on which script made which plot. Was here::here() used? If not, do we have access to the full paths used? Is there any raw-data that should be backed up that is not backed up right now? Make a list of the main software used and highlight any software that is new to us, in case we need to check more about it before the author of the code leaves. Someone with familiarity of the biological context (e.g. single-cell cell types), does the code make sense? "],["r-session-information-1.html", "R session information", " R session information If you find any typos or issues, please let us know through github.com/lcolladotor/bioc_team_ds. Thank you! This book was last updated on 2023-03-16 21:32:28. Details on the R version used for making this book. The source code is available at lcolladotor/bioc_team_ds. ## Load the package at the top of your script library(&quot;sessioninfo&quot;) ## Reproducibility information print(&#39;Reproducibility information:&#39;) ## [1] &quot;Reproducibility information:&quot; Sys.time() ## [1] &quot;2023-03-16 21:32:28 UTC&quot; proc.time() ## user system elapsed ## 1.213 0.159 1.308 options(width = 120) session_info() ## ─ Session info ─────────────────────────────────────────────────────────────────────────────────────────────────────── ## setting value ## version R version 4.1.3 (2022-03-10) ## os Ubuntu 20.04.4 LTS ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz UTC ## date 2023-03-16 ## pandoc 2.17.1.1 @ /usr/local/bin/ (via rmarkdown) ## ## ─ Packages ─────────────────────────────────────────────────────────────────────────────────────────────────────────── ## package * version date (UTC) lib source ## BiocManager 1.30.20 2023-02-24 [1] RSPM (R 4.1.0) ## BiocStyle 2.22.0 2021-10-26 [1] Bioconductor ## bookdown 0.33 2023-03-06 [1] RSPM (R 4.1.0) ## bslib 0.4.2 2022-12-16 [2] RSPM (R 4.1.0) ## cachem 1.0.7 2023-02-24 [2] RSPM (R 4.1.0) ## cli 3.6.0 2023-01-09 [2] RSPM (R 4.1.0) ## digest 0.6.31 2022-12-11 [2] RSPM (R 4.1.0) ## evaluate 0.20 2023-01-17 [2] RSPM (R 4.1.0) ## fastmap 1.1.1 2023-02-24 [2] RSPM (R 4.1.0) ## htmltools 0.5.4 2022-12-07 [2] RSPM (R 4.1.0) ## jquerylib 0.1.4 2021-04-26 [2] CRAN (R 4.1.3) ## jsonlite 1.8.4 2022-12-06 [2] RSPM (R 4.1.0) ## knitr 1.42 2023-01-25 [2] RSPM (R 4.1.0) ## R6 2.5.1 2021-08-19 [2] RSPM (R 4.1.0) ## rlang 1.1.0 2023-03-14 [2] RSPM (R 4.1.0) ## rmarkdown 2.20 2023-01-19 [2] RSPM (R 4.1.0) ## rstudioapi 0.14 2022-08-22 [2] RSPM (R 4.1.0) ## sass 0.4.5 2023-01-24 [2] RSPM (R 4.1.0) ## sessioninfo * 1.2.2 2021-12-06 [2] RSPM (R 4.1.0) ## xfun 0.37 2023-01-31 [2] RSPM (R 4.1.0) ## yaml 2.3.7 2023-01-23 [2] RSPM (R 4.1.0) ## ## [1] /__w/_temp/Library ## [2] /usr/local/lib/R/site-library ## [3] /usr/local/lib/R/library ## ## ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
